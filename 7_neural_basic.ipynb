{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "7. neural_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoz/mlclass/blob/master/7_neural_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWXv3ToA4WAt"
      },
      "source": [
        "import numpy as np \n",
        "import  matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55r99TzT4WA7"
      },
      "source": [
        "# 신경망의 기초\n",
        "\n",
        "\n",
        "신경망은 컴퓨터의 역사와 거의 동시에 시작되었다고 해도 과언이 아닐 정도로 오래된 학문이다. 하지만 오랜동안 단층신경망에 대한 연구가 중심을 이뤘고 단층신경망의 한계에 대한 지적(XOR 문제) 에 의해 한때 긴 침채기를 맞은 후에 다시 다층 신경망 오류 역전파 모델에 의해 그 한계를 극복하고 부활하였다. 본 자료에서는 신경망의 기초가 되는 가장 기초적인 수렴에 의한 문제해결방법을 고찰해 보고, 역전파모델의 기초가 되는 경사하강법에 대해 학습해본다. \n",
        "*이탤릭체 텍스트*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HLxD9ijVXef"
      },
      "source": [
        "\n",
        "\n",
        "##  수렴에 의한 단순 회귀분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2GqAUxSVuwV"
      },
      "source": [
        "### 데이터 만들기\n",
        "\n",
        "먼저 x * 2 = y 에 오차가 포함된 데이터를 상정해보자.  이때 1부터 10까지의 랜덤한 가중치를 알아내야 한다고 가정해보자.  x 는 0부터 1까지의 값을 20개로 나누고 오차값은 0을 중심으로 0.1 의 표준편차이 랜덤치로 생성한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuOrFi2v4WA8"
      },
      "source": [
        "x = np.linspace(0,1,20)\n",
        "y = x * 2 + np.random.normal(0, 0.1,20)\n",
        "\n",
        "plt.plot(x,y,'.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvyy1XmaV_S2"
      },
      "source": [
        "이제 이 데이터의 오차를 최소화하는 w 를 회귀분석 라이브러리 없이 찾아보자. \n",
        "\n",
        "### w 초기값 랜덤 생성 \n",
        "\n",
        "이를 위해 먼저 아무거나 랜덤한 w 값을 설정해보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k1hUPePX7rv"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "print(\"init w :\",w_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIZqmNsLYitN"
      },
      "source": [
        "### 오차값 계산 \n",
        "\n",
        "각 x 의 오차 d는 다음의 식에 의해서 생성한다. \n",
        "\n",
        "```\n",
        "d = y - x * w \n",
        "```\n",
        "이제 모든 x 에 대해 y 와 오차를 출력해보자. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck5kC-e5ZAVX"
      },
      "source": [
        "for i in range( len(x) ) : \n",
        "  d = y[i] - x[i] * w \n",
        "  print(y[i] - x[i] * w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f358Z1hDaEbI"
      },
      "source": [
        "### 크면 작게 작으면 크게 \n",
        "\n",
        "이제 아주 단순한 방법으로 w 를 변경해보도록 하겠다. \n",
        "```\n",
        "d 가 0보다 크면 w 값을 키우고 0보다 작으면 w를 줄인다. \n",
        "```\n",
        "이때 변화량은 일단 0.1로 고정하고 프로그램을 작성해보도록 한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4FQvl4Faohg"
      },
      "source": [
        "for i in range( len(x) ) : \n",
        "  d = y[i] - x[i] * w \n",
        "  if d > 0 : \n",
        "    w = w + 0.1\n",
        "  else:\n",
        "    w = w - 0.1  \n",
        "  print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZP1s0h9beh6"
      },
      "source": [
        "\n",
        "#### <font color = 'chocolate'>실습: d 의 변화량을 그려보기 \n",
        "w를 초기화하고 이 코드를 n 회 반복해서 실행해 w가 기울기에 가까워져가는 과정을 도식화해보자. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCPChsPfdwHa"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "\n",
        "#실습 코드를 작성해보세요\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqyPqtUx4WA9"
      },
      "source": [
        "### d에 비례해서 적용\n",
        "\n",
        "위의 방식은 수렴의 속도가 일정하며 후반에 0.1을 기준으로 진동이 발생할 확률이 높다.  하지만 오차가 크면 변화량을 늘이는 방법은 어떨까?  이제 다음의 방법을 적용해 보도록 하겠다. \n",
        "\n",
        "```\n",
        "    d = y - x * w  \n",
        "    w += d * 0.1 \n",
        "```\n",
        "\n",
        "이제 이것을 모든 x[i], y[i] 에 대해 처리하는 것을 10번 반복한 후에 w 값을 보도록하자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grlo_wn-4WA9"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "\n",
        "ws, ds = [],[]\n",
        "for step in range(10):\n",
        "    for i in range(len(x)) :\n",
        "        d = (y[i] - x[i] * w)               \n",
        "        w += d * 0.1\n",
        "\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nib7SIW4WA-"
      },
      "source": [
        "w 가 원래 설정한 계수에 근접한 것을 볼 수 있을것이다. 이렇게 오차량에 비례하여 변화량을 조절함으로서 우리가 원하는 수치에 근접해가는 것을 알 수 있댜.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_6Q7_mCiQei"
      },
      "source": [
        "\n",
        "#### <font color = 'chocolate'>실습: d 의 변화량을 그려보기 2\n",
        "이번에도 w를 초기화하고 w와 d 의 변화를 그래프로 그린 후에 고정 변화량과 비례 변화량의 수렴속도를 비교해보자. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CF2J5Ob4WA-"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "# 실습의 코드를 작성하세요\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHna6zsa4WA-"
      },
      "source": [
        "### d 의 합산 값으로 수렴\n",
        "\n",
        "d에 비례해 변화량을 정하는 방식은 고정 변화량에 비해 더 안정적이고 빠르다. 하지만  개별 데이터에 대해 이를 처리하기 때문에 완전한 수렴이 안되며 후반에 진동이 발생한다.\n",
        "\n",
        "사실 회귀분석은 전체 데이터 x 에 대해 최소값을 구하는 것이므로 이번에는 전체 데이터에 대한 오차값을 구하는 방법이 더 효율적이다. 단 전체 d 의 합산값에 대해 처리하므로 이번엔 계수를 0.01로 맞춰주도록 하겠다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtL9KyZ74WA-"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "ds,ws  = [],[]\n",
        "for step in range(700):   \n",
        "  d = 0\n",
        "  for i in range(len(x)) :\n",
        "    d += (y[i] - x[i] * w) \n",
        "  w += d * 0.01\n",
        "  ds = ds + [d]\n",
        "  ws = ws + [w]\n",
        "\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "plt.plot(ws)\n",
        "plt.show()\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILLYEMkKk0XM"
      },
      "source": [
        "상당히 깔끔하게 그려진 것을 볼 수 있다. 그런데 \n",
        "```\n",
        "d = 0\n",
        "for i in range(len(x)) :\n",
        "  d += (y[i] - x[i] * w) \n",
        "```\n",
        "\n",
        "이 코드는 다음과 같이 더 간단히 할 수 있다. \n",
        "\n",
        "```\n",
        "d = np.sum(y - x * w)\n",
        "```\n",
        "\n",
        "이제 위의 코드를 간략화시켜 완성시켜본다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Qks6FYl2-K"
      },
      "source": [
        "w = np.random.random() * 10 \n",
        "ds,ws  = [],[]\n",
        "for step in range(700):   \n",
        "  d = np.sum(y - x * w)\n",
        "  w += d * 0.01\n",
        "  ds = ds + [d]\n",
        "  ws = ws + [w]\n",
        "\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "plt.plot(ws)\n",
        "plt.show()\n",
        "\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSaSsKj_4WA_"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "<hr>\n",
        "\n",
        "## 다중 회귀분석 해보기 \n",
        "\n",
        "이번에는 두개의 입력값 x1, x2 에 대해 다음과 같은 공식으로 생성된 x,y 를 상정해 보겠다. \n",
        "```\n",
        "y =  x1 * 2 + x2 * -4\n",
        "```\n",
        "이제 이 데이터를 회귀분석 하는 방법에 대해 생각해보도록 하겠다.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFJBKruVn_BT"
      },
      "source": [
        "### 다중 회귀 데이터 만들기 \n",
        "\n",
        "우선 weight 는 2개가 필요하며 -10~10 사이의 값으로 생성한다. \n",
        "```\n",
        "w = np.random.random(2) * 20 - 10\n",
        "```\n",
        "x1, x2 도 만들어주도록 하겠다.  이번에는 x1, x2 는 순차적인 값이 아닌 0~1 사이의 랜덤값으로 생성한다. \n",
        "```\n",
        "x = np.random.random((n,2))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7EkZhd0pS-p"
      },
      "source": [
        "\n",
        "#### <font color = 'chocolate'>실습: y 값을 만들기 \n",
        "위의 x (x1, x2) 에 대해 y = x1 * 2 + x2 * -4 인 y 값을 만들되 위와 마찬가지로  표준편차 0.1 의 오차를 지니도록 생성해보자. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5CGscH1nELy"
      },
      "source": [
        "n = 20 # 데이터 갯수\n",
        "w = np.random.random(2) * 20 - 10\n",
        "x = np.random.random((n,2))\n",
        "# y값을 직접 만들어보세요 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HifIQ566nOx6"
      },
      "source": [
        "### 단순회귀처럼 다중회귀 적용\n",
        "\n",
        "이제 위의 단순회귀분석처럼 다중 회귀 분석 코드를 작성해보자. 이번에는 다시 개별 x[i] 에 대해 오차를 구하고 w 값에 변화를 주도록 하자. \n",
        "```\n",
        "for i in range(len(x)):\n",
        "  d = y[i] - np.sum( x[i] * w )  \n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHb_-aUC4WA_"
      },
      "source": [
        "w = np.random.random(2) * 20 - 10\n",
        "ds,ws  = [],[]\n",
        "for step in range(20):   \n",
        "  for i in range(len(x)):\n",
        "    d = y[i] - np.sum( x[i] * w ) \n",
        "    w += d * 0.1  \n",
        "  ds = ds + [np.abs(d)]\n",
        "  ws = ws + [w]\n",
        "\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "print(w,d)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbL48p9i1Jc9"
      },
      "source": [
        "아마 그래프가 수렴하지만 0에 수렴하지는 안을 것이다. 이는 두 w 값이 동시에 같은 변경값을 같기 때문에 각각의 수렴을 거치지 못하면서 생기는 문제이다. 요컨데 단순히 오차값을 통해 같은 변경값을 w1, w2 에 적용시키는 것으로는 문제가 해결되지 안는다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3YX_Yu04WA_"
      },
      "source": [
        "### 오차를 분배하기 \n",
        "\n",
        "두개 이상의 입력값과 그 입력값들의 계수 w에 의해 발생한 오차값을 이용해 각각의 w 를 수렴시킬 수 있을까?  그 문제에 대한 답은 \n",
        "\n",
        "```\n",
        "오차값을 x 의 크기에 따라 분배한다 \n",
        "```\n",
        "이다.  요컨데 x1,x2 = 0.1,1 에 의해 오차가 3 이 발생했다면 w1 은 오차값에 다시 x1 의 값인 0.1 을 곱해주고 w2 는 x2 인 1 을 곱해서 적용시켜주는 것이다. 요컨데 \n",
        "```\n",
        "오차값에 기여도를 입력 값으로부터 부여\n",
        "```\n",
        "의 원리이다.  이것을 코드에 적용하면 다음과 같다. \n",
        "\n",
        "```\n",
        "w += d * 0.1  \n",
        "=> \n",
        "w += d * 0.1 * x[i]\n",
        "```\n",
        "\n",
        "이제 이것을 적용하여 코드를 돌려보고 그 결과를 보도록하자 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8i49Rb0MsU"
      },
      "source": [
        "w = np.random.random(2) * 20 - 10\n",
        "ds,ws  = [],[]\n",
        "for step in range(100):   \n",
        "  for i in range(len(x)):\n",
        "    d = y[i] - np.sum( x[i] * w )  \n",
        "    w += d * x[i] * 0.1  \n",
        "  ds = ds + [np.abs(d)]\n",
        "  ws = ws + [w]\n",
        "\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "print(w,d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4WTck-3htm"
      },
      "source": [
        "이제 실제로 우리가 처음 적용한 계수 2와 -4 에 근접해가는 것을 볼 수 있을 것이다.  이것이 여러개의 입력 값에 해당하는 계수를 맞춰가는 원리이며 신경망이 많은 입력 값이 특정 출력값에 수렴하도록 계숙값을 변화시켜가는 근본원리이다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIN7tNuQ42gW"
      },
      "source": [
        "### 행렬연산으로 변경하기 \n",
        "\n",
        "그렇다면 이이 분배방식은 반드시 개별 x 에 대해 연산이 이뤄져야 하는가?  그렇지 안다.  x 와 오차값을 다시 한번 출력해보도록하자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnKN-HBP5R2m"
      },
      "source": [
        "for i in range(len(x)):\n",
        "  d = y[i] - np.sum( x[i] * w )  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve8munni5i7K"
      },
      "source": [
        "이것은 다음의 연산으로 한번에 배열로 바꿀 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EALJcSW05xia"
      },
      "source": [
        "d = y - np.sum( x * w , axis = 1 )\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvWsqf1g54MO"
      },
      "source": [
        "여기에 x 값을 곱하면 어떨까?  하지만 x 는 n * 2 의 행렬이고 d 는 n 행렬이므로 둘을 곱하기 위해선 n * 1 행렬로 바꿔줘야한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h881Im96K3v"
      },
      "source": [
        "print( d.reshape(-1,1) * x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNnFepf86SIR"
      },
      "source": [
        "이 값은 각각 w1, w2 에 적용되는 비율이다. 그리고 이들을 세로축(axis=0) 으로 합산하면 w1, w2 에 적용되야 하는 변경값들이 합산된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_xupqGj6ucC"
      },
      "source": [
        "print( np.sum( d.reshape(-1,1) * x, axis = 0 ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDRElYp64D7"
      },
      "source": [
        "이들은 전체 변경값의 합산값이므로 0.01 의 변경률을 적용시키도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMl3u3HC6-fb"
      },
      "source": [
        "w += np.sum( d.reshape(-1,1) * x, axis = 0 ) * 0.01\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi6BQl2i7JJh"
      },
      "source": [
        "#### <font color = 'chocolate'>실습: 다중 회귀 간략화하기\n",
        "위의 코드를 적용해 다중회귀를 numpy 연산을 통해 전체 변경값을 한번에 구해 처리할 수 있도록 간략화하세요. 또한 그래프로 d 의 변화를 출력할 수 있는 방법을 찾으세요\n",
        "</font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPpYX0fz7UWK"
      },
      "source": [
        "w = np.random.random(2) * 20 - 10\n",
        "ds,ws  = [],[]\n",
        "for step in range(100): \n",
        "\n",
        "  # 아래의 코드를 간략화시키고 d 값의 그래프를 그릴 수 있도록 변경하세요  \n",
        "  '''\n",
        "  for i in range(len(x)):\n",
        "    d = y[i] - np.sum( x[i] * w )  \n",
        "    w += d * x[i] * 0.1  \n",
        "  ds = ds + [np.abs(d)]\n",
        "  '''\n",
        "\n",
        "  ws = ws + [w]\n",
        "\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "print(w,d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP2_LPOx4WBI"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "<hr> \n",
        "\n",
        "## 분류와 Sigmoid 함수\n",
        "\n",
        "이번에는 분류문제를 해결해보자. 분류문제중에 가장 간단한 or 문제를 먼저 생각해보자. 무척 간단하다고 생각할 지도 모르겠다.  위에서 직선의 연관성을 도출한 것에 비하면 이것이 훨씬 쉽게 느껴질 수도 있다. 먼저 데이터를 만들어보자. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbLPnt94WBI"
      },
      "source": [
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,1,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce6vkPGW4WBJ"
      },
      "source": [
        "이제 위에서 사용한 알고리즘을 돌려보도록 하자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NNYhkY-86c"
      },
      "source": [
        "n,dm = 4,2\n",
        "w_init = np.random.random(dm)\n",
        "w = w_init.copy()\n",
        "ds = np.array([])\n",
        "for step in range(100):         \n",
        "    d = y - np.sum(x * w, axis = 1)    \n",
        "    w += np.sum(x * w * d.reshape(n,1), axis = 0) * 0.1 \n",
        "    ds = np.append(ds,np.abs(d).sum())        \n",
        "print(\"result:\", np.dot(x,w), \"error:\",ds[-1].round(4))  \n",
        "plt.plot(ds)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0z8EXNd4WBL"
      },
      "source": [
        "우리가 원하는 답은 0,1,1,1 이지만 알고리즘의 출력은 0,0.6, 0.6 1.3  정도가 나올 것이다.  왜 이런 문제가 생길까? \n",
        "\n",
        "정답은 0,1 에도 1을  만들고 1,0 에도 1을 만들지만 1,1 에도 1을 만드는 방법은 없다는 것이다. 왜냐하면 우리가 사용하는 방법은 단순히 입력에 가중치를 더해서 합산하는 방법에 지나지 않기 때문이다.  이런 방식은 실수값을 예측하는 회귀문제에는 잘 맞지만 범주형 데이터를 다루는 분류문제에는 적합하지 안다. \n",
        "\n",
        "이런 문제를 해결하기 위해서는 어떤 현상이 발생하는 확률을 계산하기 위한 함수인 sigmoid 함수가 적합하다. 이 함수의 정의는 다음과 같다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYcLcIKa4WBL"
      },
      "source": [
        "def sig(x):\n",
        "    return 1 / ( 1 + np.exp(-x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyUkllXZ4WBL"
      },
      "source": [
        "이 함수는 결과적으로 다음과 같은 형태를 띄며 결국 모든 값을 0 ~ 1 사이로 만들어 버린다. 그리고 경계를 기점으로 기울기가 양쪽으로 다 0 에 수렴한다.  결국 이 함수를 이용하면 0과 1 같은 상태를 표현하는데 적합하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFvFeOaz4WBL"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "x = np.linspace(-10,10,100)\n",
        "y = sig(x)\n",
        "plt.plot(x,y)\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1LyAdwC4WBM"
      },
      "source": [
        "이제 이 함수를 사용해 위의 예제를 풀어보도록 하겠다. 이번에는 좀더 많은 시행을 시켜보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkgua5Bq4WBM"
      },
      "source": [
        "n,dm = 4,2\n",
        "w_init = np.random.random(dm)\n",
        "w = w_init.copy()\n",
        "ds = np.array([])\n",
        "for step in range(1000):         \n",
        "    o = sig(np.sum(x * w, axis = 1) ) \n",
        "    d = y - o \n",
        "    w += np.sum(x * w * d.reshape(n,1), axis = 0) * 0.1 \n",
        "    ds = np.append(ds,np.abs(d).sum())        \n",
        "print(\"result:\", sig( np.dot(x,w) ), \"error:\",ds[-1].round(4))  \n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wMRuHp4WBM"
      },
      "source": [
        "이제 3가지 결과값은 상당히 1에 근접한 것을 볼 수 있다. 또한 학습또한 1을 넘김으로서 발생하는 오차에 구애받지 않고 가중치를 증가시켰음을 알 수 있다. 하지만 0,0 의 값이 0.5 가 나온 것에 대한 불만이 있을 것이다. 이것은 위의 sigmoid 함수가 -무한대 부터 +무한대 까지의 범위를 받는 함수이기에 발생하는 문제이다. \n",
        "\n",
        "이것은 sig 함수를 다음과 같이 변경해서 해결이 가능하다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ehsd8t_4WBM"
      },
      "source": [
        "def sig(x):\n",
        "    return 1 / ( 1 + np.exp(x * -10 + 5) )\n",
        "x = np.linspace(0,1,100)\n",
        "y = sig(x)\n",
        "plt.plot(x,y)\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4xqxsTw4WBM"
      },
      "source": [
        "비슷하게 느껴질 수도 있지만 위의 sigmoid 함수는 0~1 까지의  값의 변화에 대응하여 0과 1에 수렴하도록 변경한 것이다. 이제 이를 이용하여  위의 예제를 다시 돌려보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c__Y-9o_4WBN"
      },
      "source": [
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,1,1,1])\n",
        "n,dm = 4,2\n",
        "w_init = np.random.random(dm)\n",
        "w = w_init.copy()\n",
        "ds = np.array([])\n",
        "for step in range(1000):         \n",
        "    o = sig(np.sum(x * w, axis = 1) ) \n",
        "    d = y - o \n",
        "    w += np.sum(x * w * d.reshape(n,1), axis = 0) * 0.1 \n",
        "    ds = np.append(ds,np.abs(d).sum())        \n",
        "print(\"result:\", sig( np.dot(x,w) ), \"error:\",ds[-1].round(4))  \n",
        "plt.plot(ds)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUrnGr74WBN"
      },
      "source": [
        "이제 값들이 상당히 근접한 것을 알 수 있다.  \n",
        "\n",
        "이번에는 위의 예를 and 로 변환해서 풀어보자. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSCbbhtD4WBN"
      },
      "source": [
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,0,0,1])\n",
        "n,dm = 4,2\n",
        "w_init = np.random.random(dm)\n",
        "w = w_init.copy()\n",
        "ds = np.array([])\n",
        "for step in range(1000):         \n",
        "    o = sig(np.sum(x * w, axis = 1) ) \n",
        "    d = y - o \n",
        "    w += np.sum(x * w * d.reshape(n,1), axis = 0) * 0.1 \n",
        "    ds = np.append(ds,np.abs(d).sum())        \n",
        "print(\"result:\", sig( np.dot(x,w) ), \"error:\",ds[-1].round(4))  \n",
        "plt.plot(ds)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlAVnQa94WBN"
      },
      "source": [
        "생각보다 결과가 좋지 안음에 갸웃할 것이다. 사실 가만히 생각해봐도 and 는 or 에 비해 훨씬 더 정교한 문제이다. 그런 문제를 다룰때 위에서 우리가 다룬 x 를 기반 오차를 결정하는 방법은 이처럼 x 가 0이나 1에 고정되는 방식일 경우 그 한계가 드러난다. 오차가 발생하는 범인은 x 만이 아니기에 우리는 여기서 w도 그 원인의 하나로 그 오차율에 영향을 고려해야 한다. \n",
        "\n",
        "이제 w의 변경치인 wd 공식을 다음과 같이 변경하도록 하겠다. \n",
        "\n",
        "$$ \\large wd = w * x * d $$\n",
        "\n",
        "이는 weight 와 x 의 연산이 필요하므로 다음과 같은 공식을 거친다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I4U_T-o4WBN"
      },
      "source": [
        "#### and gate 해결법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39NRTohQ4WBN"
      },
      "source": [
        "\n",
        "\n",
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,0,0,1])\n",
        "n,dm = 4,2\n",
        "w_init = np.random.random(dm)\n",
        "w = w_init.copy()\n",
        "ds = np.array([])\n",
        "for step in range(10000):         \n",
        "    o = sig( np.sum(x * w, axis = 1))\n",
        "    d = y - o\n",
        "    wd =  np.sum( (x * w).T * d , axis = 1) \n",
        "    w += wd     \n",
        "    ds = np.append(ds,np.abs(d).sum())      \n",
        "print(\"result:\", sig( np.dot(x,w) ).round(4), \"error:\",ds[-1].round(4))  \n",
        "plt.plot(ds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSuS5W1p4WBO"
      },
      "source": [
        "## xor 문제와 다층 신경망 \n",
        "\n",
        "위에서 우리가 다룬 것은 초기 학자들이 연구하던 단층 신경망의 예이다. 당시에는 이러한 분류에 대한 수학적인 방법론들이 정립되지 안았기 때문에 이런 단층 신경망으로 문제를 해결하는 것도 놀랍게 느껴졌지만 결국 이러한 신경망은  \n",
        "\n",
        "$$ y = w1x1 + w2x2 + ..  $$\n",
        "\n",
        "의 구조를 지니며 이것은 1차원이든 2차원이든 3차원이든 직선이나 평면에 의한 문제의 분류밖에 해결하지 못한다는 것이 증명되고 그 한계로 XOR 문제가 제시되었다. \n",
        "\n",
        "XOR 문제는 간단한다. \n",
        "\n",
        "0,0 -> 0\n",
        "0,1 -> 1\n",
        "1,0 -> 1\n",
        "1,1 -> 0 \n",
        "\n",
        "이 되며 이는 결과적으로 평면상에 다음과 같은 형태로 표현된다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vFjQaniY4WBO"
      },
      "source": [
        "plt.scatter([0,0,1,1],[0,1,0,1], c=[0,1,1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cAnDKy64WBP"
      },
      "source": [
        "이 문제를 해결하기 위해 나온 이론이 입력과  출력사이에 중간레이어를 두는 방법이다.  지금까지 우리가 다뤘던 신경망이 다음과 같은 구조라면 \n",
        "\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F261AC64E56C2D0E7241637\" \n",
        "    width = 400\n",
        "    style = \"float:left\"     \n",
        "    title = \"출처: https://untitledtblog.tistory.com/27\" > \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMBpNID64WBP"
      },
      "source": [
        "\n",
        "다층 신경망은 다음과 같은 구조를 지닌다. 단, 아래에는 은닉층이 하나인 경우에 대한 예시일 뿐이지만 은닉층은 얼마든지 여러층으로 만들 수 있다. \n",
        "\n",
        "<img src = \"https://mblogthumb-phinf.pstatic.net/MjAxNzA2MTZfMzQg/MDAxNDk3NTc4MDc4NTU4.C0svtndk_igat9FquGev3il4HWs2mEKarZPuzI0kgMcg.75f89hjNck6eLQNZWQ4-QZiWNnArNKnuEXvxoL3n0aAg.PNG.samsjang/%EC%BA%A1%EC%B2%98.PNG?type=w2\" \n",
        "    width = 600\n",
        "    style = \"float:left\"     \n",
        "    title = \"출처: https://m.blog.naver.com/samsjang/221030487369\" > \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNBmmi794WBP"
      },
      "source": [
        "이와 같은 간단한 발상을 왜 못했을까? 하는 생각이 들 것이다. 하지만 오류를 최소화하는 1차원적인 발상으로는 저 은닉층을 거치는 weight 값을 어떻게 처리해야 할지 당시에는 몰랐다.  그리고 이 문제를 해결한 것이 '오류역전파 모델' 이다. \n",
        "\n",
        "### 오류 역전파 모델 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fek6R4Bg4WBQ"
      },
      "source": [
        "위의 예제에서 우리는 오류에 대한 책임을 죄다 w 에 돌려버렸다. 당연한것이 입력인 x는 고정되어있기 때문에 우리가 수정 가능한 것은  w 밖에 없었기 때문이다. 하지만 역전파 모델에서는 그 입력의에도 책임을 돌린다.그래야 은닉층의 오류를 기반으로 다시 그 이전계층의 가중치 w 에 대한 수정이 가해지기 때문이다. \n",
        "\n",
        "위의 그림을 기준으로 입력을 i ,은닉을 h, 출력을 o 라고 할 경우 신경망이 결과를 도출하는 과정은  i -> h -> o 의 형태로 이뤄지지만 망에 대한 수정은 o -> h -> i 방향으로 진행된다. 이것은 여러개의 은닉층을 가진 경우에도 마찬가지로 역으로  진행되기에 '역전파 모델' 이라고 불리우며 현재까지 모든 신경망 학습의 기본원리이다. \n",
        "\n",
        "\n",
        "역전파 과정을 좀더 자세히 표현하면 \n",
        "\n",
        "- 출력층의 에러 d_out 을 구한다. \n",
        "- d_out 을 기반으로 w_h2o 를 업데이트한다. \n",
        "- 은닉층의 에러 d_hidden 을 구한다. \n",
        "- d_hidden 을 기반으로 w_i2h 를 업데이트한다. \n",
        "\n",
        "이것의 수학적 모델은 매우 심플하다. w 는 w 가 오류에 얼마나 어떤 방향으로 영향을 주었는가를 기준으로 그 수치를 업데이트 하고 은닉층은 은닉층의 값이 얼마나 어떤 방향으로 오류에 영향을 주었는가를 계산한다. w 의 오류는 w 값의 변화로서 영향을 주며 은닉층의 오류는 다시 이를 기준으로 그 이전계층의 w 오류를 계산하는데 사용된다. \n",
        "\n",
        "다만 좀더 세밀히 접근하면 단순히 값에 영향을 준 사실 보다도 그 x 가 오류에 얼마나 큰 차이를 준 것인지 기울기를 구하여 그 조정양을 조절하게 되는데 이때 미분이 사용된다. 하지만 이 부분은 지금은 무시하고 영향력을 중심으로 생각해도 좋다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV5Gnlhm4WBQ"
      },
      "source": [
        "이제 이를 기반으로 xor 문제를 풀 수 있도록 다계층 신경망을 생각해보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6wH4msG4WBQ"
      },
      "source": [
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,1,1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10lOugBg4WBQ"
      },
      "source": [
        "일단 은닉층은 하나의 층으로 해보도록 하겠다. 그리고 은닉층의 노드숫자는 hn 으로 정의한다. 그러면 입력->은닉의 가중치들의 숫자는 dm * hn 이 되고 은닉 -> 출력의 가중치의 숫자는 hn 이 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiybKqNw4WBQ"
      },
      "source": [
        "n,hn,dm = 4,3,2                 # 데이터 갯수, 히든 노드, 입력 노드수\n",
        "w1 = np.random.random((hn,dm))  # 은닉층 가중치\n",
        "w2 = np.random.random(hn)       # 출력층 가중치\n",
        "print(\"w1:\\n\",w1,\"\\nw2:\\n\",w2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOFIh1lw4WBQ"
      },
      "source": [
        "이제 이를 이용해 x 의 입력을 y로 전달하는 과정을 만들어보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFFyJDmO4WBR"
      },
      "source": [
        "h = sig( np.dot( x, w1.T ))\n",
        "print(h)\n",
        "o = sig( np.sum( h * w2 , axis = 1) ).round(4)\n",
        "print(o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G09_Qh84WBR"
      },
      "source": [
        "이번엔 이를 통해 업데이트 값을 계산해보자. 위에서 다룬 방식으로 업데이트 값을 계산해보도록 하겠다. sigp 는 sigmoid 함수의 미분함수로 sigp(x) 는 x(1-x) 이다. 이 부분까지 고려하면 너무 복잡하니 그냥 x 라고 생각하는게 더 편할듯하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyXdItO4WBR"
      },
      "source": [
        "d = d = (y - o)*sigp(o)\n",
        "wd2 = h.T.dot( d ) * lr\n",
        "\n",
        "print(wd2)\n",
        "w2 += wd2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnjbKBAP4WBR"
      },
      "source": [
        "이제 hidden 의 오차를 계산해보자. 은닉층의 오차는 출력 가중치와 출력오차의 곱이 되며 여기에 x 를 반영해주면 은닉계층의 가중치의 변동값이 나온다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygjumTpc4WBS"
      },
      "source": [
        "hd = d.reshape(-1,1).dot(w2.reshape(-1,1).T)\n",
        "print(hd)\n",
        "wd1 = x.T.dot(hd) \n",
        "print(wd1)\n",
        "w1 += wd1 * lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cTXAWXC4WBS"
      },
      "source": [
        "그런데 여기에 한가지 빼먹은게 있다. 실제 학습에서는 곱 연산만으로는 모든 값의 범위를 대응하기 어렵기 때문에 이런 문제를 쉽게 해결하기 위해 각 출력마다 전체적인 범위를 조정하는 bias 라고 하는 값을 지닌다. 이들은 모든 출력에 포함되며 역전파시에도 직접적으로 조정치를 얻는다. 현재 우리가 다루는 네트워크에서는 은닉과 출력 2개의 값에 bias 를 줄 수 있기에 이를 반영하면  정방향처리는 다음과 같이 바꿀 수 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh-IDqob4WBS"
      },
      "source": [
        "b1,b2 = 0\n",
        "\n",
        "h = sig( np.dot( x, w1.T ) + b1)\n",
        "o = sig( np.sum( h * w2 , axis = 1) + b2 ).round(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C6X1Q-S4WBS"
      },
      "source": [
        "또한 바이어스의 업데이트는 바로 직접적인 조정을 받기 때문에 출력층과 은닉층의 바이어스는 다음과 같이 업데이트된다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nun5Vg9z4WBS"
      },
      "source": [
        "b2 += d * lr \n",
        "b1 += hd * lr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90dTU5oz4WBT"
      },
      "source": [
        "위의 모든 사항을 반영하여 신경망을 완성하면 다음과 같다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgIq728R4WBT"
      },
      "source": [
        "x = np.array([[0,0], [0,1], [1,0], [1,1]] )\n",
        "y = np.array([0,1,1,0])\n",
        "n,hn,dm = 4,2,2\n",
        "b1,b2 = 0,0\n",
        "w1 = np.random.random((hn,dm))\n",
        "w2 = np.random.random(hn)\n",
        "lr = 0.01\n",
        "\n",
        "def sigp(x):\n",
        "    return x  * (1-x)\n",
        "\n",
        "ds = np.array([])\n",
        "for step in range(100000):         \n",
        "    h = sig( np.dot( x, w1.T ) + b1)\n",
        "    o = sig( np.sum( h * w2 , axis = 1) + b2 ).round(4) \n",
        "    d = (y - o)*sigp(o)\n",
        "    \n",
        "    \n",
        "    wd2 = h.T.dot( d ) * lr\n",
        "    \n",
        "    hd = d.reshape(-1,1).dot(w2.reshape(-1,1).T)\n",
        "    wd1 = x.T.dot(hd) \n",
        "    \n",
        "    w2 += wd2 * lr    \n",
        "    b2 += d * lr    \n",
        "    w1 += wd1 * lr\n",
        "    b1 += hd * lr \n",
        "    if step % 100 == 0 :\n",
        "        ds = np.append(ds,np.abs(d).sum())        \n",
        "    \n",
        "\n",
        "print(\"result:\", o , \"error:\",ds[-1].round(4))  \n",
        "#print(b)\n",
        "plt.plot(ds)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}