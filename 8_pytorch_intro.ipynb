{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMnWRvjWoVFWnLpYiI2tqn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoz/mlclass/blob/master/8_pytorch_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6IcySOqTwL"
      },
      "source": [
        "import torch as tc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly_XpcwEqUsg"
      },
      "source": [
        "#PyTorch Start\n",
        "\n",
        "파이토치는 페이스북 AI 리서치 랩이 만들고 2016년 공개한 오픈소스 머신 라이브러리이다. 인공지능 라이브러리로서는 케라스, 텐서플로등에 비해 늦게 합류하였으나 상당히 빠른 속도와 함게 다양한 형태의 모델의 개발이 자유롭기 때문에 점점 사용자가 늘어나고 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ0g8a9cqXvv"
      },
      "source": [
        "## Tensor \n",
        "\n",
        "파이토치는 텐서라는 매트릭스 데이터를 기반으로 이뤄져있다는 점에서 Numpy 와 매우 유사하다.  하지만 GPU 연산을 지원한다는 점과 딥러닝을 위한 자동미분모듈을 사용할 수 있다는 점등에서 딥러닝용으로 차별화된다. 또한 텐서 연산을 이용한 저수준 모델 구성이 가능할 뿐만 아니라 부터 케라스와 유사한 다양한 표준 모델등이 지원된다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgWWp04WVMEp"
      },
      "source": [
        "### Tensor 와 Numpy\n",
        "\n",
        "그러면 이제 텐서의 선언을 한번 보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS8JANYvqwO3",
        "outputId": "51626855-c417-4c8e-9013-247e5e853c5e"
      },
      "source": [
        "t = tc.FloatTensor([1,2,3])\n",
        "t"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GRGR2N_y1hI"
      },
      "source": [
        "Numpy 를 연상시키는 익숙한 코드일 것이다. 물론 Numpy 의 리스트로도 만들 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLp2tCS9q0FO",
        "outputId": "4c88d400-9bd9-4632-a29d-35cb522b5d7e"
      },
      "source": [
        "import numpy as np\n",
        "n = np.array([[3,4],[5,6]])\n",
        "t  = tc.FloatTensor(n)\n",
        "print(t)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfDFUkXrzkdm"
      },
      "source": [
        "다음 코드는 Numpy 가 Torch 에 끼친 영향을 느낄 수 있다. size 라는 자체 배열의 정보를 제공하는 함수가 있지만 Numpy 와 같은 shape 도 사용이 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5PfJD1q-8u",
        "outputId": "30bb36f9-d627-4fe6-e234-61c70eee68d3"
      },
      "source": [
        "print( t.dim() )\n",
        "print( t.size() )\n",
        "print( t.shape )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEno_MSW1YFn"
      },
      "source": [
        "또한 로우 칼럼 연산도 Numpy 와 유사하게 지원한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Mn_clwrJRG",
        "outputId": "0dcd5568-1c4d-4fcd-da81-681af1987b75"
      },
      "source": [
        "import torch as tc \n",
        "\n",
        "t1,t2 = tc.FloatTensor([[1,2,3,4]]),tc.FloatTensor([[1],[2],[3]])\n",
        "print(t1 * t2)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.],\n",
            "        [ 2.,  4.,  6.,  8.],\n",
            "        [ 3.,  6.,  9., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLZattlZ4oe7"
      },
      "source": [
        "### mean,max,min, argmax\n",
        "\n",
        "Torch 는 Numpy에서 지원하는 함수와 같은 함수를 지원하는 경우가 많다. 아래 몇몇 연산을 한번 알아보자 먼저 평균을 구하는 함수이다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Pr4gRU1-gW",
        "outputId": "2040f2a1-f605-4a8f-ff12-3eedb0c13108"
      },
      "source": [
        "a = np.array([1,2,3])\n",
        "print(a.mean())\n",
        "\n",
        "t = tc.FloatTensor([1,2,3])\n",
        "print(t.mean())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Ucpyiv2xsb"
      },
      "source": [
        "미묘한 차이를 발견할 수 있다. np는 그 결과가 일반 정수로 리턴되는데 tc 는 그 결과값도 텐서임을 알 수 있다. 이는 모든 계산이 gpu 상에서 연속적으로 이뤄져야하기 때문이다. \n",
        "\n",
        "또한 배열단위의 연산의 경우 Numpy 와 유사하게 기준축을 설정할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e88xgn8sJsu",
        "outputId": "65a994ea-2fe6-4df8-e99f-e881ac499b80"
      },
      "source": [
        "t = t1 + t2\n",
        "print(t)\n",
        "print( t.mean() )\n",
        "print( t.mean(dim = 0) )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4., 5.],\n",
            "        [3., 4., 5., 6.],\n",
            "        [4., 5., 6., 7.]])\n",
            "tensor(4.5000)\n",
            "tensor([3., 4., 5., 6.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkEu3upm3kJQ"
      },
      "source": [
        "min, max 는 최소 최대값을 구하는 함수이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkxpLKT4sY22",
        "outputId": "f43f2c39-4747-48c8-e228-f23c764d2e4c"
      },
      "source": [
        "print( t )\n",
        "print( t.max() )\n",
        "print( t.min(dim = 0))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor(3.)\n",
            "torch.return_types.min(\n",
            "values=tensor(1.),\n",
            "indices=tensor(0))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbC1nabT4BKm"
      },
      "source": [
        "argmax, argmin 은 최대, 최소값의 인덱스를 알려준다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aIqsVqXtH4H",
        "outputId": "ebb78511-9853-44c3-d207-e005d21bff85"
      },
      "source": [
        "print( t.argmax() )\n",
        "print( t.argmin(dim = 0))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11)\n",
            "tensor([0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRPNh2A24Q6X"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 데이터 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvyz0azH44iH"
      },
      "source": [
        "### view\n",
        "\n",
        "Numpy 에서 reshape 가 중요한 역할을 했던걸 기억할 것이다 Tensor 는 이와 유사한 역할을 하는 함수로 view 를 제공한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSXXnwTxtdPA",
        "outputId": "5507d7d5-8dbd-4921-a9a8-5d3f0bde6815"
      },
      "source": [
        "print(t)\n",
        "print( t.view([4,3]) )\n",
        "print( t.view(2,6) )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4., 5.],\n",
            "        [3., 4., 5., 6.],\n",
            "        [4., 5., 6., 7.]])\n",
            "tensor([[2., 3., 4.],\n",
            "        [5., 3., 4.],\n",
            "        [5., 6., 4.],\n",
            "        [5., 6., 7.]])\n",
            "tensor([[2., 3., 4., 5., 3., 4.],\n",
            "        [5., 6., 4., 5., 6., 7.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy7BhTXqty03",
        "outputId": "a9483eaf-9ae7-430f-8f75-82ad4de06df6"
      },
      "source": [
        "t.view([-1,2])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [4., 5.],\n",
              "        [3., 4.],\n",
              "        [5., 6.],\n",
              "        [4., 5.],\n",
              "        [6., 7.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvVNmDJI5AH2"
      },
      "source": [
        "### Squeeze , Unsqueeze\n",
        "\n",
        "의외로 종종 등장하는 함수로서 squeeze 와 Unsqueeze 라는 함수가 있다. Squeeze 는 축을 하나 없애는 역할을 하고 Unsueeze 는 축을 추가하는 역할을 한다. 물론 view 를 사용하는 방법도 있지만 이를 쓰는 경우도 있으니 알아두자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuHs8T2ZupBv",
        "outputId": "5ff9901a-26ee-4548-9e02-b9ff8f2da769"
      },
      "source": [
        "t = tc.IntTensor([1,2,3,4,5])\n",
        "t = t.view(1,1,5,1)\n",
        "print(t)\n",
        "\n",
        "\n",
        "print( t.squeeze().shape )\n",
        "print( t.squeeze(0).shape )\n",
        "print( t.squeeze(1).shape )\n",
        "print( t.squeeze(2).shape ) # 해당 차원의 크기가 1이 아니면 아무일도 일어나지 안는다\n",
        "print( t.squeeze(3).shape )\n",
        "print( t.squeeze(-1).shape ) # 제일 뒤 차원"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[1],\n",
            "          [2],\n",
            "          [3],\n",
            "          [4],\n",
            "          [5]]]], dtype=torch.int32)\n",
            "torch.Size([5])\n",
            "torch.Size([1, 5, 1])\n",
            "torch.Size([1, 5, 1])\n",
            "torch.Size([1, 1, 5, 1])\n",
            "torch.Size([1, 1, 5])\n",
            "torch.Size([1, 1, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzs7OFGxt_3P",
        "outputId": "30fe1e96-46d0-4b61-c54a-acdfcedd4ac0"
      },
      "source": [
        "t = tc.IntTensor([1,2,3,4,5])\n",
        "print( t.unsqueeze(-1).shape  ) # -1 은 가장 뒤 차원을 의미\n",
        "print( t.unsqueeze(-1) )\n",
        "print()\n",
        "print( t.unsqueeze(0).shape  )\n",
        "print( t.unsqueeze(0) ) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5]], dtype=torch.int32)\n",
            "\n",
            "torch.Size([1, 5])\n",
            "tensor([[1, 2, 3, 4, 5]], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPX1mwT45LYq"
      },
      "source": [
        "### Cat, Stack\n",
        "\n",
        "두 데이터를 하나의 데이터로 합치는 방법으롤 cat 과 stack 이 있다. cat 은 numpy의 concatenate 와 마찬가지로 두 데이터를 합친다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYONAsG5zK1A",
        "outputId": "cb3a6c44-3022-40ae-a2f5-63a672776ae0"
      },
      "source": [
        "t1,t2 = tc.FloatTensor([1,2,3]),tc.FloatTensor([4,5,6])\n",
        "\n",
        "print( tc.cat([t1,t2]), \"\\n\" )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6.]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdCR3AqC8S3h"
      },
      "source": [
        "1개 이상의 축을 가진 배열이라면 디폴트값은 첫 축을 기준으로 수행된다.  특정 축을 지정할때는 Numpy와 유사하게 dim 옵션을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW9EboAH0Jdp",
        "outputId": "825059d6-bd0b-40eb-c477-455805d73ad6"
      },
      "source": [
        "t1,t2 = tc.FloatTensor([[1,2,3]]),tc.FloatTensor([[4,5,6]])\n",
        "print( tc.cat([t1,t2]) )\n",
        "print( tc.cat([t1,t2], dim = 1) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3., 4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFOqK_999rIK"
      },
      "source": [
        "stack 의 경우 cat 과 유사하지만 데이터를 합칠대 축을 추가한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "untrqLMZw_nS",
        "outputId": "859caefc-09b2-477f-b2b3-c1d2e02068e4"
      },
      "source": [
        "\n",
        "t1,t2 = tc.FloatTensor([1,2,3]),tc.FloatTensor([4,5,6])\n",
        "\n",
        "print(tc.stack([t1,t2]) )\n",
        "print(tc.stack([t1,t2], dim = 1) )\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9cn6Qfr5QcB"
      },
      "source": [
        "### zeros_like, ones_like\n",
        "\n",
        "np.zeros(), np.ones() 와 유사하게 tc 에서도 0이나 1로 가득찬 텐서를 생성할 수 있다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEGfu1FI-0xC",
        "outputId": "3bc5acb1-5ed0-46ce-e7a3-d476db12675c"
      },
      "source": [
        "print( tc.zeros((2,2)) ) \n",
        "print( tc.ones(4))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_lFUzyh_ATd"
      },
      "source": [
        "하지만 특정 텐서와 같은 형태를 만들 수도 있는데 zeros_like, ones_like 이라는 함수가 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh8NgsTo2SvJ",
        "outputId": "1c5a86f7-94af-4322-e7e9-9413c4b396d0"
      },
      "source": [
        "print(t)\n",
        "\n",
        "print(tc.zeros_like(t))\n",
        "print(tc.ones_like(t))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[11., 12., 13., 14.],\n",
            "        [21., 22., 23., 24.],\n",
            "        [31., 32., 33., 34.]])\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiNO4qP4-b4E",
        "outputId": "b8373393-ea03-46eb-b5f1-0fac742d1c94"
      },
      "source": [
        "print( np.ones(4) )"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbKRCgftAri5"
      },
      "source": [
        "### inplace operation\n",
        "\n",
        "어떤 텐서에 특정 값을 더하는 연산은 t = t + 3 이라고 할 수도 있지만 이는 메모리상에 t+3 이라는 배열을 생성한 후에 이를 대처하는 과정을 갖는다. 텐서의 크기가 거대할 경우 이는 속도에 무시못할 영향을 미친다. 어떤 값을 더하거나 교체할 경우 gpu 상에서는 이런 과정 없이 현재의 텐서상에 바로 업데이트를 할 필요가 있다. 이를 inploace operation 이라고 한다. \n",
        "\n",
        "예를 들어 t라는 텐서에 대해 t.mul(2) 은 t * 2 의 배열을 새로 생성한다. 만일 이를 다른 곳에 대입하지 안으면 그 후에 소멸되고 만다. 하지만 t.mul_ 는 inplace 연산으로서 연산 자체가 t 의 값을 업데이트해준다.  이는 메모리나 속도상에 큰 이점이 있으므로 특정 텐서를 업데이트 할때는 이 연산을 사용하는데 익숙해져야한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9N9bGh2j6n",
        "outputId": "b4aa538d-b6c5-41fe-f620-472a16cb0a1f"
      },
      "source": [
        "print(t.mul(2) ) \n",
        "print(t)\n",
        "print() \n",
        "print(t.mul_(2))\n",
        "print(t)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUUoRlr320qa",
        "outputId": "b44a67dc-6fda-4e38-ba58-9c814b4fe0fd"
      },
      "source": [
        "print(t)\n",
        "\n",
        "t.add_(1)\n",
        "print(t)\n",
        "\n",
        "t.sub_(10)\n",
        "print(t)\n",
        "\n",
        "t.div_(10)\n",
        "print(t)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[11., 12., 13., 14.],\n",
            "        [21., 22., 23., 24.],\n",
            "        [31., 32., 33., 34.]])\n",
            "tensor([[12., 13., 14., 15.],\n",
            "        [22., 23., 24., 25.],\n",
            "        [32., 33., 34., 35.]])\n",
            "tensor([[ 2.,  3.,  4.,  5.],\n",
            "        [12., 13., 14., 15.],\n",
            "        [22., 23., 24., 25.]])\n",
            "tensor([[0.2000, 0.3000, 0.4000, 0.5000],\n",
            "        [1.2000, 1.3000, 1.4000, 1.5000],\n",
            "        [2.2000, 2.3000, 2.4000, 2.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrK6bpMh4Tk4"
      },
      "source": [
        "### Numpy <-> Torch\n",
        "\n",
        "torch 가 많은 numpy 의 기능을 제공하지만 그럼에도 그 목적이 다르기 때문에 보다 광범위한 numpy 의 연산을 사용해 초기 데이터를 생성할 수 있다. 이를 위해서는 numpy와 torch 사이의 데이터 변형이 필요할 수 있다.  \n",
        "\n",
        "아래는 numpy -> torch 로의 데이터 변환을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPYMXy2b3NpA",
        "outputId": "673e04b4-f0df-4d28-cc28-92696b7752ca"
      },
      "source": [
        "n = np.array([1,2,3,4,5], dtype = 'float')\n",
        "\n",
        "t = tc.from_numpy(n)\n",
        "print(n)\n",
        "print(t)\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 2. 3. 4. 5.]\n",
            "tensor([1., 2., 3., 4., 5.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GvHPO4GDbgP"
      },
      "source": [
        "torch 를 numpy로 변환하는 경우 텐서에 .numpy() 메소드를 제공한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C570niZ4GMR",
        "outputId": "b4d1ce8a-4a51-4955-fadb-cbf9be40f480"
      },
      "source": [
        "print(t.numpy())\n",
        "print( type( t.numpy() ) )"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 2. 3. 4. 5.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0zj-tjXUOSO"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "파이토치가 단순한 행렬 연산라이브러리가 아닌 이유는 모든 연산에 대한 추적이 가능하기 때문이다. 특히 특정 변수가 결과를 도출하는 연산을 추적해 그 변수값의 미분값을 계산해준다. 이런 기능을 autograd 라고 한다. \n",
        "\n",
        "이를 위해서 텐서에 다음과 같이 선언한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSw6YQfDmq7"
      },
      "source": [
        "w = tc.tensor(1.0, requires_grad = True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g6wj4vnVduY"
      },
      "source": [
        "이제 이를 통한 연산을 한번 만들어보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3zCo6jvVcTT",
        "outputId": "f34e804e-2b8b-4654-a064-d27d72ae9ca0"
      },
      "source": [
        "y = w * 2 \n",
        "print(y)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2., grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PAUDv7-VnF8"
      },
      "source": [
        "이 연산에 대한 w 의 미분은 2이다. 이것을 하기 위해 이제 역추적 명령을 실행한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rClWFM7aV_lI"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n9equ2kWCZP"
      },
      "source": [
        "이젠 w 의 미분값을 확인해보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO2Gzuk6WBoY",
        "outputId": "52136114-0eec-4bd5-d46d-a7cdeaba23dc"
      },
      "source": [
        "print( w.grad )"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlNEOpn2WLuf"
      },
      "source": [
        "\n",
        "이제 위의 과정을 합쳐서 좀더 복잡한 연산의 미분값을 확인해보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHGITvb5WKYW",
        "outputId": "7cf1a8d3-7ee6-459b-df03-ddea15d05e83"
      },
      "source": [
        "\n",
        "w = tc.tensor(1.0, requires_grad = True)\n",
        "y = 3 * w ** 2  + 2 * w\n",
        "y.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dny1F-wgYKjn"
      },
      "source": [
        "이러한 미분값이 무슨 의미가 있을까?  하는 생각이 들 것이다.  회귀분석에서 우리가 수행했던 \n",
        "\n",
        "> $ w \\times x + b $ \n",
        "\n",
        "에서 w 값을 변경할때 \n",
        "\n",
        "> $ w' = lr \\times x \\times d$\n",
        "\n",
        "라는 공식을 사용한 기억이 날 것이다. 신경망에서 찾아야 하는 답은 입력값 x 가 아니라 x 값에 대해 오차를 최소화하는 w 이다. 그리고 x 는 w 입장에서 미분 계수가 된다. sigmoid 함수에서는 sigp 라는 미분 함수를 쓴 기억이 날 것이다. 이 역시 x 에 대한 미분을 사용하는 효과가 있다. 요컨데 모든 경우 미분계수를 사용하여 오차를 줄이는 방향과 양을 결정할 수 있다. \n",
        "\n",
        "그러면 이제 이것을 활용하여 회귀문제를 풀어보도록 하겠다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wEb-qyVYI0d"
      },
      "source": [
        "import numpy as np \n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + np.random.normal(0,0.3,10)\n",
        "\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "print(x,y)\n",
        "\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "print(w)\n",
        "\n",
        "for step in range(100):\n",
        " \n",
        "  o = x * w\n",
        "  d = (y - o).mean() \n",
        "  print(w)\n",
        "\n",
        "  d.backward()\n",
        "  with tc.no_grad(): # 왠지 모르지만 grad 를 연산에 사용하려면 필요\n",
        "    w -= 0.01 * w.grad * d\n",
        "    w.grad.zero_()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZkZZxlkXiVc"
      },
      "source": [
        "## Optimizer \n",
        " \n",
        "autograd 는 오차값을 최소화시켜주는 w의 변경값을 위한 미분값을 찾아주지만 그럼에도 신경망이 복잡하고 계층이 깊어지면 이런 모든 작업을 직접 하는 것은 상당히 골치아픈 일이다.  다행히 torch 에는 이런 과정을 자동화하는 기능을 지원한다.  이를 Optimizer 라고 한다. \n",
        "\n",
        "이를 위해서는 다음 서브라이브러리를 호출해야한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7BEQFTWik-"
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN0Z8mWmlPL9"
      },
      "source": [
        "그리고 먼저 optimizer 를 생성한다. 여기서는 가장 기본적은 경사하강법(SGD) 을 사용하도록 하겠다.  이때 첫번째 인자로는 최적화 변수들을 선택해야 한다. 이 변수들은 반드시 requires_grad 설정이 되어있어야 한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFYZw1rbkkh0"
      },
      "source": [
        "optimizer = optim.SGD([w], lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-upY5s7mhne"
      },
      "source": [
        "학습은 다음과 같은 과정으로 이뤄진다. \n",
        "\n",
        "- 오차 계산\n",
        "- optimizer.zero_grad() : grad 초기화 \n",
        "- d.backward()  : grad 계산\n",
        "- optimizer.step() : w 값 업데이트\n",
        "\n",
        "그러면 위의 문제를 optimizer 를 사용해 풀어보도록 하겠다. 먼저 x,y 를 만들고 w 를 초기화 한 후에 optimizer 를 생성한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsCZyDnBnVQ2"
      },
      "source": [
        "# 데이터 초기화 \n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + np.random.normal(0,0.3,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "\n",
        "# 옵티마이저 생성\n",
        "optimizer = optim.SGD([w], lr = 0.01)\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjKcxSton9Oi"
      },
      "source": [
        "이제 다음의 과정을 반복한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUhE45lgnXbt",
        "outputId": "335f3df8-1521-4ffd-ad1e-4c2e109b128f"
      },
      "source": [
        "o = w * x \n",
        "d = ( y - o ).mean() \n",
        "\n",
        "optimizer.zero_grad()\n",
        "d.backward()\n",
        "optimizer.step() \n",
        "\n",
        "print(\"w:{:.3f} err:{:.3f}\".format(w.item(), d.item()) )\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:4.960 err:-11.352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI5Cl28goltl"
      },
      "source": [
        "? 어 그런데 반복할수록 오히려 w 가 기하급수적으로 커지고 큰 수치로 마이너스로 떨어지며 수렴하지 안는것을 볼 수 있을것이다.  이는 \n",
        "\n",
        ">  경사하강법은 오차를 최소화하는 방향으로 작동한다. \n",
        "\n",
        "요컨데 - 라도 최소화면 가능하면 그 방향으로 움직인다는 것이다.  이를 해결하기 위해서는 d 를 계산할때 제곱을 해주면 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll2lyLO4oc3m",
        "outputId": "803fad42-90ef-4a66-c21a-fe01b6460f55"
      },
      "source": [
        "o = w * x \n",
        "d = ( y - o ).pow(2).mean() \n",
        "\n",
        "optimizer.zero_grad()\n",
        "d.backward()\n",
        "optimizer.step() \n",
        "\n",
        "print(\"w:{:.3f} err:{:.3f}\".format(w.item(), d.item()) )\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:2.006 err:0.099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FTVh0thpPsF"
      },
      "source": [
        ""
      ],
      "execution_count": 152,
      "outputs": []
    }
  ]
}