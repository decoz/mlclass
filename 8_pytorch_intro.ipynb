{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAPbA5fomYtpQBBlv9ekIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoz/mlclass/blob/master/8_pytorch_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6IcySOqTwL"
      },
      "source": [
        "import torch as tc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly_XpcwEqUsg"
      },
      "source": [
        "#PyTorch Start\n",
        "\n",
        "파이토치는 페이스북 AI 리서치 랩이 만들고 2016년 공개한 오픈소스 머신 라이브러리이다. 인공지능 라이브러리로서는 케라스, 텐서플로등에 비해 늦게 합류하였으나 상당히 빠른 속도와 함게 다양한 형태의 모델의 개발이 자유롭기 때문에 점점 사용자가 늘어나고 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ0g8a9cqXvv"
      },
      "source": [
        "## Tensor \n",
        "\n",
        "파이토치는 텐서라는 매트릭스 데이터를 기반으로 이뤄져있다는 점에서 Numpy 와 매우 유사하다.  하지만 GPU 연산을 지원한다는 점과 딥러닝을 위한 자동미분모듈을 사용할 수 있다는 점등에서 딥러닝용으로 차별화된다. 또한 텐서 연산을 이용한 저수준 모델 구성이 가능할 뿐만 아니라 부터 케라스와 유사한 다양한 표준 모델등이 지원된다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgWWp04WVMEp"
      },
      "source": [
        "### Tensor 와 Numpy\n",
        "\n",
        "그러면 이제 텐서의 선언을 한번 보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS8JANYvqwO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154a5ca5-24be-4dd1-c033-0956cfd593af"
      },
      "source": [
        "t = tc.FloatTensor([1,2,3])\n",
        "t = tc.tensor([1.0, 2.0, 3.0])\n",
        "t"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GRGR2N_y1hI"
      },
      "source": [
        "Numpy 를 연상시키는 익숙한 코드일 것이다. 물론 Numpy 의 리스트로도 만들 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLp2tCS9q0FO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084f41c2-a316-40ee-ea70-99382c22a478"
      },
      "source": [
        "import numpy as np\n",
        "n = np.array([[3,4],[5,6]])\n",
        "t  = tc.FloatTensor(n)\n",
        "print(t)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfDFUkXrzkdm"
      },
      "source": [
        "다음 코드는 Numpy 가 Torch 에 끼친 영향을 느낄 수 있다. size 라는 자체 배열의 정보를 제공하는 함수가 있지만 Numpy 와 같은 shape 도 사용이 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs5PfJD1q-8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042630a5-a22d-4dba-840d-0e01f244ec73"
      },
      "source": [
        "print( t.dim() )\n",
        "print( t.size() )\n",
        "print( t.shape )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEno_MSW1YFn"
      },
      "source": [
        "또한 로우 칼럼 연산도 Numpy 와 유사하게 지원한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Mn_clwrJRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04b4fac-7919-45d4-e12a-8563a812f584"
      },
      "source": [
        "import torch as tc \n",
        "\n",
        "t1,t2 = tc.FloatTensor([[1,2,3,4]]),tc.FloatTensor([[1],[2],[3]])\n",
        "print(t1 * t2)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.],\n",
            "        [ 2.,  4.,  6.,  8.],\n",
            "        [ 3.,  6.,  9., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLZattlZ4oe7"
      },
      "source": [
        "### mean,max,min, argmax\n",
        "\n",
        "Torch 는 Numpy에서 지원하는 함수와 같은 함수를 지원하는 경우가 많다. 아래 몇몇 연산을 한번 알아보자 먼저 평균을 구하는 함수이다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Pr4gRU1-gW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231a4bb2-268a-41cb-db38-87c6755e2a8a"
      },
      "source": [
        "a = np.array([1,2,3])\n",
        "print(a.mean())\n",
        "\n",
        "t = tc.FloatTensor([1,2,3])\n",
        "print(t.mean())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Ucpyiv2xsb"
      },
      "source": [
        "미묘한 차이를 발견할 수 있다. np는 그 결과가 일반 정수로 리턴되는데 tc 는 그 결과값도 텐서임을 알 수 있다. 이는 모든 계산이 gpu 상에서 연속적으로 이뤄져야하기 때문이다. \n",
        "\n",
        "또한 배열단위의 연산의 경우 Numpy 와 유사하게 기준축을 설정할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e88xgn8sJsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ec676e-4bd7-49b5-e18e-4ed3d0a85fc3"
      },
      "source": [
        "t = t1 + t2\n",
        "print(t)\n",
        "print( t.mean() )\n",
        "print( t.mean(dim = 0) )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4., 5.],\n",
            "        [3., 4., 5., 6.],\n",
            "        [4., 5., 6., 7.]])\n",
            "tensor(4.5000)\n",
            "tensor([3., 4., 5., 6.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkEu3upm3kJQ"
      },
      "source": [
        "min, max 는 최소 최대값을 구하는 함수이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkxpLKT4sY22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9927b9-f739-4832-fac5-9d628bf4502a"
      },
      "source": [
        "print( t )\n",
        "print( t.max() )\n",
        "print( t.min(dim = 0))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor(3.)\n",
            "torch.return_types.min(\n",
            "values=tensor(1.),\n",
            "indices=tensor(0))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbC1nabT4BKm"
      },
      "source": [
        "argmax, argmin 은 최대, 최소값의 인덱스를 알려준다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIqsVqXtH4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d35c3c-6715-477b-a54e-d230c9d657b4"
      },
      "source": [
        "print( t.argmax() )\n",
        "print( t.argmin(dim = 0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2)\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvyz0azH44iH"
      },
      "source": [
        "### view\n",
        "\n",
        "Numpy 에서 reshape 가 중요한 역할을 했던걸 기억할 것이다 Tensor 는 이와 유사한 역할을 하는 함수로 view 를 제공한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSXXnwTxtdPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8510ef13-9d7c-4e84-81bd-3e5c2bcb7265"
      },
      "source": [
        "\n",
        "\n",
        "print(t)\n",
        "print( t.view([4,3]) )\n",
        "print( t.view(2,6) )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4., 5.],\n",
            "        [3., 4., 5., 6.],\n",
            "        [4., 5., 6., 7.]])\n",
            "tensor([[2., 3., 4.],\n",
            "        [5., 3., 4.],\n",
            "        [5., 6., 4.],\n",
            "        [5., 6., 7.]])\n",
            "tensor([[2., 3., 4., 5., 3., 4.],\n",
            "        [5., 6., 4., 5., 6., 7.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7BhTXqty03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d6d368-d903-43b5-b9a1-be6e849716c1"
      },
      "source": [
        "t.view([-1,2])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [4., 5.],\n",
              "        [3., 4.],\n",
              "        [5., 6.],\n",
              "        [4., 5.],\n",
              "        [6., 7.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvVNmDJI5AH2"
      },
      "source": [
        "### Squeeze , Unsqueeze\n",
        "\n",
        "의외로 종종 등장하는 함수로서 squeeze 와 Unsqueeze 라는 함수가 있다. Squeeze 는 축을 하나 없애는 역할을 하고 Unsueeze 는 축을 추가하는 역할을 한다. 물론 view 를 사용하는 방법도 있지만 이를 쓰는 경우도 있으니 알아두자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuHs8T2ZupBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9188205a-a7ac-459a-dfae-9826bdeb807a"
      },
      "source": [
        "t = tc.IntTensor([1,2,3,4,5])\n",
        "t = t.view(1,1,5,1)\n",
        "print(t)\n",
        "\n",
        "\n",
        "print( t.squeeze().shape )\n",
        "print( t.squeeze(0).shape )\n",
        "print( t.squeeze(1).shape )\n",
        "print( t.squeeze(2).shape ) # 해당 차원의 크기가 1이 아니면 아무일도 일어나지 안는다\n",
        "print( t.squeeze(3).shape )\n",
        "print( t.squeeze(-1).shape ) # 제일 뒤 차원"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[1],\n",
            "          [2],\n",
            "          [3],\n",
            "          [4],\n",
            "          [5]]]], dtype=torch.int32)\n",
            "torch.Size([5])\n",
            "torch.Size([1, 5, 1])\n",
            "torch.Size([1, 5, 1])\n",
            "torch.Size([1, 1, 5, 1])\n",
            "torch.Size([1, 1, 5])\n",
            "torch.Size([1, 1, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzs7OFGxt_3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f0ecad-c17c-4c32-8575-4d75b4de722d"
      },
      "source": [
        "t = tc.IntTensor([1,2,3,4,5])\n",
        "print( t.unsqueeze(-1).shape  ) # -1 은 가장 뒤 차원을 의미\n",
        "print( t.unsqueeze(-1) )\n",
        "print()\n",
        "print( t.unsqueeze(0).shape  )\n",
        "print( t.unsqueeze(0) ) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5]], dtype=torch.int32)\n",
            "\n",
            "torch.Size([1, 5])\n",
            "tensor([[1, 2, 3, 4, 5]], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPX1mwT45LYq"
      },
      "source": [
        "### Cat, Stack\n",
        "\n",
        "두 데이터를 하나의 데이터로 합치는 방법으롤 cat 과 stack 이 있다. cat 은 numpy의 concatenate 와 마찬가지로 두 데이터를 합친다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYONAsG5zK1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd3317a-9030-47ce-878f-846869c055b0"
      },
      "source": [
        "t1,t2 = tc.FloatTensor([1,2,3]),tc.FloatTensor([4,5,6])\n",
        "\n",
        "print( tc.cat([t1,t2]), \"\\n\" )\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6.]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdCR3AqC8S3h"
      },
      "source": [
        "1개 이상의 축을 가진 배열이라면 디폴트값은 첫 축을 기준으로 수행된다.  특정 축을 지정할때는 Numpy와 유사하게 dim 옵션을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW9EboAH0Jdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b4945f-b3ad-47de-ed9c-89f25758f23e"
      },
      "source": [
        "t1,t2 = tc.FloatTensor([[1,2,3]]),tc.FloatTensor([[4,5,6]])\n",
        "print( tc.cat([t1,t2]) )\n",
        "print( tc.cat([t1,t2], dim = 1) )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3., 4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFOqK_999rIK"
      },
      "source": [
        "stack 의 경우 cat 과 유사하지만 데이터를 합칠대 축을 추가한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "untrqLMZw_nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd56034a-ed75-42d0-a8ae-cc4c3ca26811"
      },
      "source": [
        "\n",
        "t1,t2 = tc.FloatTensor([1,2,3]),tc.FloatTensor([4,5,6])\n",
        "\n",
        "print(tc.stack([t1,t2]) )\n",
        "print(tc.stack([t1,t2], dim = 1) )\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9cn6Qfr5QcB"
      },
      "source": [
        "### zeros_like, ones_like\n",
        "\n",
        "np.zeros(), np.ones() 와 유사하게 tc 에서도 0이나 1로 가득찬 텐서를 생성할 수 있다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEGfu1FI-0xC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3106c7-c00b-40a5-b880-913d31df47c0"
      },
      "source": [
        "print( tc.zeros((2,2)) ) \n",
        "print( tc.ones(4))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_lFUzyh_ATd"
      },
      "source": [
        "하지만 특정 텐서와 같은 형태를 만들 수도 있는데 zeros_like, ones_like 이라는 함수가 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh8NgsTo2SvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddfe33a-8400-4764-d220-6452064dd6d3"
      },
      "source": [
        "print(t)\n",
        "\n",
        "print(tc.zeros_like(t))\n",
        "print(tc.ones_like(t))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n",
            "tensor([0, 0, 0, 0, 0], dtype=torch.int32)\n",
            "tensor([1, 1, 1, 1, 1], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiNO4qP4-b4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb92dca-4ff2-4ff4-9ce8-2d7e02599416"
      },
      "source": [
        "print( np.ones(4) )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbKRCgftAri5"
      },
      "source": [
        "### inplace operation\n",
        "\n",
        "어떤 텐서에 특정 값을 더하는 연산은 t = t + 3 이라고 할 수도 있지만 이는 메모리상에 t+3 이라는 배열을 생성한 후에 이를 대처하는 과정을 갖는다. 텐서의 크기가 거대할 경우 이는 속도에 무시못할 영향을 미친다. 어떤 값을 더하거나 교체할 경우 gpu 상에서는 이런 과정 없이 현재의 텐서상에 바로 업데이트를 할 필요가 있다. 이를 inploace operation 이라고 한다. \n",
        "\n",
        "예를 들어 t라는 텐서에 대해 t.mul(2) 은 t * 2 의 배열을 새로 생성한다. 만일 이를 다른 곳에 대입하지 안으면 그 후에 소멸되고 만다. 하지만 t.mul_ 는 inplace 연산으로서 연산 자체가 t 의 값을 업데이트해준다.  이는 메모리나 속도상에 큰 이점이 있으므로 특정 텐서를 업데이트 할때는 이 연산을 사용하는데 익숙해져야한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym9N9bGh2j6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1611444-b652-41be-faa6-40d9db77ade4"
      },
      "source": [
        "print(t.mul(2) ) \n",
        "print(t)\n",
        "print() \n",
        "print(t.mul_(2))\n",
        "print(t)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2,  4,  6,  8, 10], dtype=torch.int32)\n",
            "tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n",
            "\n",
            "tensor([ 2,  4,  6,  8, 10], dtype=torch.int32)\n",
            "tensor([ 2,  4,  6,  8, 10], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUUoRlr320qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0420ad-7162-4b2e-cd48-8bafa63daee3"
      },
      "source": [
        "t = tc.tensor([1.0,2.0,3.0])\n",
        "print(t)\n",
        "\n",
        "t.add_(1)\n",
        "print(t)\n",
        "\n",
        "t.sub_(10)\n",
        "print(t)\n",
        "\n",
        "t.div_(10)\n",
        "print(t)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([2., 3., 4.])\n",
            "tensor([-8., -7., -6.])\n",
            "tensor([-0.8000, -0.7000, -0.6000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrK6bpMh4Tk4"
      },
      "source": [
        "### Numpy <-> Torch\n",
        "\n",
        "torch 가 많은 numpy 의 기능을 제공하지만 그럼에도 그 목적이 다르기 때문에 보다 광범위한 numpy 의 연산을 사용해 초기 데이터를 생성할 수 있다. 이를 위해서는 numpy와 torch 사이의 데이터 변형이 필요할 수 있다.  \n",
        "\n",
        "아래는 numpy -> torch 로의 데이터 변환을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPYMXy2b3NpA"
      },
      "source": [
        "n = np.array([1,2,3,4,5], dtype = 'float')\n",
        "\n",
        "t = tc.from_numpy(n)\n",
        "print(n)\n",
        "print(t)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GvHPO4GDbgP"
      },
      "source": [
        "torch 를 numpy로 변환하는 경우 텐서에 .numpy() 메소드를 제공한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C570niZ4GMR"
      },
      "source": [
        "print(t.numpy())\n",
        "print( type( t.numpy() ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0zj-tjXUOSO"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "파이토치가 단순한 행렬 연산라이브러리가 아닌 이유는 모든 연산에 대한 추적이 가능하기 때문이다. 특히 특정 변수가 결과를 도출하는 연산을 추적해 그 변수값의 미분값을 계산해준다. 이런 기능을 autograd 라고 한다. \n",
        "\n",
        "이를 위해서 텐서에 다음과 같이 선언한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSw6YQfDmq7"
      },
      "source": [
        "w = tc.tensor(1.0, requires_grad = True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g6wj4vnVduY"
      },
      "source": [
        "이제 이를 통한 연산을 한번 만들어보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3zCo6jvVcTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d89234c-78bc-412e-cdb9-10927fa86e6b"
      },
      "source": [
        "y = w * 2 \n",
        "print(y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2., grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PAUDv7-VnF8"
      },
      "source": [
        "이 연산에 대한 w 의 미분은 2이다. 이것을 하기 위해 이제 역추적 명령을 실행한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rClWFM7aV_lI"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n9equ2kWCZP"
      },
      "source": [
        "이젠 w 의 미분값을 확인해보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2Gzuk6WBoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a82791d-34a1-493b-db2e-bd204fd5aa57"
      },
      "source": [
        "print( w.grad )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlNEOpn2WLuf"
      },
      "source": [
        "\n",
        "이제 위의 과정을 합쳐서 좀더 복잡한 연산의 미분값을 확인해보도록 하겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHGITvb5WKYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f195d9-fbe7-45ee-e6b9-c1ae8f99ef16"
      },
      "source": [
        "\n",
        "w = tc.tensor(1.0, requires_grad = True)\n",
        "y = 3 * w ** 2  + 2 * w\n",
        "\n",
        "y.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dny1F-wgYKjn"
      },
      "source": [
        "이러한 미분값이 무슨 의미가 있을까?  하는 생각이 들 것이다.  회귀분석에서 우리가 수행했던 \n",
        "\n",
        "> $ w \\times x + b $ \n",
        "\n",
        "에서 w 값을 변경할때 \n",
        "\n",
        "> $ w' = lr \\times x \\times d$\n",
        "\n",
        "라는 공식을 사용한 기억이 날 것이다. 신경망에서 찾아야 하는 답은 입력값 x 가 아니라 x 값에 대해 오차를 최소화하는 w 이다. 그리고 x 는 w 입장에서 미분 계수가 된다. sigmoid 함수에서는 sigp 라는 미분 함수를 쓴 기억이 날 것이다. 이 역시 x 에 대한 미분을 사용하는 효과가 있다. 요컨데 모든 경우 미분계수를 사용하여 오차를 줄이는 방향과 양을 결정할 수 있다. \n",
        "\n",
        "그러면 이제 이것을 활용하여 회귀문제를 풀어보도록 하겠다. 우선 전에 다뤘던 방식과 조금 차이가 필요하다. \n",
        "\n",
        "- epoch 를 한번에 처리해야 하기 때문에 오차는 제곱오차를 사용한다. \n",
        "- 미분을 사용하면 따로 d 값을 곱하지 안아도 된다. \n",
        "\n",
        "epoch 단위의 오차의 합산을 구할 시에는 음수오차와 양수오차가 서로 0을 만들 수가 있다. 이를 방지하기 위해서는 절대값이 필요한데 절대값은 미분계수를 구하기 어렵기 때문에 간편한 제곱을 사용하는 것이 좋다. \n",
        "\n",
        "또한 미분 자체가 기울기에서 d 의 크기를 어느정도 반영하게 된다. 특히 제곱오차의 경우 d 값이 너무 커서 미분계수를 아주 작게 잡지 안으면 쉽게 발산하므로 d 값 자체를 사용하지 안도록 하겠다. \n",
        "\n",
        "그리고 텐서의 값을 출력하기 위해서는 .item()을 사용해야 일반적인 실수 출력을 얻을 수 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wEb-qyVYI0d"
      },
      "source": [
        "import numpy as np \n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + np.random.normal(0,0.3,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "print(x,y)\n",
        "\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "print(w)\n",
        "\n",
        "for step in range(100):\n",
        " \n",
        "  o = x * w\n",
        "  d = (y - o).pow(2).mean() \n",
        "  print(\"{:.3f}\".format( w.item()) )\n",
        "\n",
        "  d.backward()\n",
        "  with tc.no_grad(): # 왠지 모르지만 grad 를 연산에 사용하려면 필요\n",
        "    w -= 0.01 * w.grad \n",
        "    w.grad.zero_()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqBZcSfKLp0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc25533b-3df7-47f6-8c53-198cb19674b8"
      },
      "source": [
        "xn = np.arange(10)\n",
        "yn = xn * 7 + 3 + np.random.normal(0,0.3,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "print(x,y)\n",
        "\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "b = tc.rand(1, requires_grad = True)\n",
        "for step in range(1000):\n",
        "  o = w * x + b\n",
        "  d = (y - o).pow(2).mean() \n",
        "  d.backward()\n",
        "\n",
        "  with tc.no_grad() :\n",
        "    w -= w.grad * 0.01\n",
        "    b -= b.grad * 0.01 \n",
        "    if step % 100  == 0 : \n",
        "      print(\"w:{:.3f} b:{:.3f} d:{:.3f}\".format( w.item() , b.item(), d.item()) )\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) tensor([ 2.8360, 10.0360, 16.9785, 24.3624, 31.4605, 37.6662, 45.3071, 51.4092,\n",
            "        58.7535, 65.5807])\n",
            "w:4.428 b:1.306 d:1310.980\n",
            "w:7.079 b:2.356 d:0.282\n",
            "w:7.024 b:2.703 d:0.154\n",
            "w:6.992 b:2.901 d:0.112\n",
            "w:6.974 b:3.012 d:0.099\n",
            "w:6.964 b:3.076 d:0.095\n",
            "w:6.959 b:3.112 d:0.093\n",
            "w:6.955 b:3.133 d:0.093\n",
            "w:6.953 b:3.144 d:0.093\n",
            "w:6.952 b:3.151 d:0.093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRPNh2A24Q6X"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : grad 사용해보기\n",
        "위의 문제에 bias 를 추가해 $ y = 2\\times x + 3$ 을 해결해보세요\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeGs3TFbLTt8"
      },
      "source": [
        "import numpy as np \n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + 3 +  np.random.normal(0,0.3,10)\n",
        "# 연습문제 코드 작성하기 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZkZZxlkXiVc"
      },
      "source": [
        "## Optimizer \n",
        " \n",
        "autograd 는 오차값을 최소화시켜주는 w의 변경값을 위한 미분값을 찾아주지만 그럼에도 신경망이 복잡하고 계층이 깊어지면 이런 모든 작업을 직접 하는 것은 상당히 골치아픈 일이다.  다행히 torch 에는 이런 과정을 자동화하는 기능을 지원한다.  이를 Optimizer 라고 한다. \n",
        "\n",
        "이를 위해서는 다음 서브라이브러리를 호출해야한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7BEQFTWik-"
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN0Z8mWmlPL9"
      },
      "source": [
        "그리고 먼저 optimizer 를 생성한다. 여기서는 가장 기본적은 경사하강법(SGD) 을 사용하도록 하겠다.  이때 첫번째 인자로는 최적화 변수들을 선택해야 한다. 이 변수들은 반드시 requires_grad 설정이 되어있어야 한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFYZw1rbkkh0"
      },
      "source": [
        "optimizer = optim.SGD([w], lr = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-upY5s7mhne"
      },
      "source": [
        "학습은 다음과 같은 과정으로 이뤄진다. \n",
        "\n",
        "- 오차 계산\n",
        "- optimizer.zero_grad() : grad 초기화 \n",
        "- d.backward()  : grad 계산\n",
        "- optimizer.step() : w 값 업데이트\n",
        "\n",
        "그러면 위의 문제를 optimizer 를 사용해 풀어보도록 하겠다. 먼저 x,y 를 만들고 w 를 초기화 한 후에 optimizer 를 생성한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsCZyDnBnVQ2"
      },
      "source": [
        "# 데이터 초기화 \n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + np.random.normal(0,0.3,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "\n",
        "# 옵티마이저 생성\n",
        "optimizer = optim.SGD([w], lr = 0.01)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjKcxSton9Oi"
      },
      "source": [
        "\n",
        "이제 다음의 과정을 반복한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUhE45lgnXbt"
      },
      "source": [
        "for step in range(100):\n",
        "  o = w * x \n",
        "  d = ( y - o ).mean() \n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  d.backward()\n",
        "  optimizer.step() \n",
        "\n",
        "  print(\"w:{:.3f} err:{:.3f}\".format(w.item(), d.item()) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI5Cl28goltl"
      },
      "source": [
        "? 어 그런데 반복할수록 오히려 w 가 기하급수적으로 커지고 큰 수치로 마이너스로 떨어지며 수렴하지 안는것을 볼 수 있을것이다.  이는 \n",
        "\n",
        ">  경사하강법은 오차를 최소화하는 방향으로 작동한다. \n",
        "\n",
        "요컨데 - 라도 최소화면 가능하면 그 방향으로 움직인다는 것이다.  이를 해결하기 위해서는 d 를 계산할때 제곱을 해주면 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll2lyLO4oc3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44b771d-8146-49a4-d491-58f9920bd2fb"
      },
      "source": [
        "o = w * x \n",
        "d = ( y - o ).pow(2).mean() \n",
        "\n",
        "optimizer.zero_grad()\n",
        "d.backward()\n",
        "optimizer.step() \n",
        "\n",
        "print(\"w:{:.3f} err:{:.3f}\".format(w.item(), d.item()) )\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:3.933 err:574.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prfqpLPkQy39"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : Optimizer 활용\n",
        "위의 예를 반복해서 d 의 값이 0.01 이하로 떨어질때까지 작동하는 반복문을 작성하고  해당 step을 출력하세요\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FTVh0thpPsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb300725-ac69-4061-f935-944574a4418e"
      },
      "source": [
        "\n",
        "xn = np.arange(10)\n",
        "yn = xn * 2 + 4 + np.random.normal(0,0.1,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "b = tc.rand(1, requires_grad = True)\n",
        "\n",
        "optimizer = optim.SGD([w,b], lr = 0.01)\n",
        "## 연습문제의 코드를 작성하세요\n",
        "for step in range(10000):\n",
        "  o = x * w + b\n",
        "  d = (y - o).pow(2).mean()\n",
        "  optimizer.zero_grad()\n",
        "  d.backward() \n",
        "  optimizer.step()    \n",
        "  if d <= 0.01 :\n",
        "    print(\"{:d}step : w:{:.3f}, b:{:.3f}, err:{:.3f}\".\\\n",
        "          format(step, w.item(), b.item(), d.item()))\n",
        "    break\n",
        "print(\"final step:\", step )\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "549step : w:2.018, b:3.853, err:0.010\n",
            "final step: 549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qhba2r9RT97"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : Optimizer 에 bias 적용\n",
        "이번에는 bias 를 적용해보세요\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewz_T6G-RT-F"
      },
      "source": [
        "xn = np.arange(10)\n",
        "yn = xn * 4 - 3 + np.random.normal(0,0.3,10)\n",
        "\n",
        "x = tc.FloatTensor(xn)\n",
        "y = tc.FloatTensor(yn)\n",
        "w = tc.rand(1, requires_grad = True)\n",
        "\n",
        "## 연습문제의 코드를 작성하세요\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}