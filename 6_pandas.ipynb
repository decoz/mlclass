{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "6. pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoz/mlclass/blob/master/6_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_6CRKVZWQk"
      },
      "source": [
        "# About Pandas\n",
        "\n",
        "Pandas : \n",
        "\n",
        "numpy 가 수치 행렬에 특화된 라이브러리라면 Pandas 는 DB등의 레코드 데이터를 다루는데 특화된 라이브러리이다. 머신러닝에서 다루는 다양한 리얼데이터들은 주로 DB나 CSV파일등 레코드 구조를 가지고 있기때문에 먼저 Pandas로 읽어들인 후 이를 다시 처리에 특화된 numpy 로 변환하는 경우가 많다.  Pandas 도 제대로 공부하려면 상당히 방대하지만 여기서는 머신러닝 데이터를 처리하기 위해 필요한 요소위주로 간략하게 다루도록 한다 \n",
        "\n",
        "앞으로는 다음 구문으로 pandas 라이브러리를 pd로 import 하여 사용하도록 하겠다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WY1VMVJpZWQp"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luygi8FTZWQq"
      },
      "source": [
        "<hr style=\"height:3px\">\n",
        "\n",
        "# Pandas 의 기초 \n",
        "\n",
        "numpy 가 numpy array 를 기본 자료구조로 처리한다고 할때 pandas 는 data frame 이라는 자료형을 기본으로 다룬다. \n",
        "\n",
        "## Data frame 수동 생성\n",
        "\n",
        "사실 많은 경우 csv 나 xlsx 파일을 읽어들이는 경우에 자주 사용되지만 간단히 만들어서 여러 테스트하기 위해서는 직접 만드는 방법을 익혀두는 것도 나쁘지 안다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mNaOtkwfZWQq"
      },
      "source": [
        "df = pd.DataFrame( {\n",
        "    'A' : [1,2,3],\n",
        "    'B' : [4,5,6]    \n",
        "})\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GreflsqxZWQr"
      },
      "source": [
        "똑같은 구조를 다음과 같은 방식으로 만들수도 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSxiKBuAZWQr"
      },
      "source": [
        "df = pd.DataFrame([[1,4], [2,5], [3,6]], columns = ['A','B'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOp9XsYUZWQr"
      },
      "source": [
        "레코드 구조를 다루는 자료 답게 index 를 생성할 수도 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xgfk-oneZWQr"
      },
      "source": [
        "df.index = ['a','b','c']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QReH_2-UZWQs"
      },
      "source": [
        "데이터 프레임의 index , column 은 다음과 같이 확인이 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7EeajMXgZWQs"
      },
      "source": [
        "print( df.index )\n",
        "print( df.columns )\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoe3G1rvZWQs"
      },
      "source": [
        "\n",
        "##  series \n",
        "\n",
        "하나의 칼럼 값들을 1차원 배열형태로 추출할 수 있는데 이것을 series 라고 한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i70xGctZZWQs"
      },
      "source": [
        "print( df['A'] )\n",
        "print( df.A )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tjo6-BHZWQt"
      },
      "source": [
        "series 를 다음과 같이 추가할 수도 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HuMyEtCSZWQt"
      },
      "source": [
        "df['C'] = [0.1,0.2], 0.3]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRI5rqteZWQt"
      },
      "source": [
        "series 를 다음과 같이 삭제할 수도 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oOjivi7IZWQt"
      },
      "source": [
        "del df['C']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzQ2yeNYZWQt"
      },
      "source": [
        "\n",
        "## Data frame 과  numpy 배열\n",
        "\n",
        "사실 pandas 는 내부적으로 값을 저장할때 numpy 배열형태로 저장한다. 그러므로 다음과 같이 간단하게 numpy 배열을 추출할 수 있다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xtqDBsj8ZWQt"
      },
      "source": [
        "arr = df.values \n",
        "print(arr)\n",
        "\n",
        "print(arr * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcoc2KplZWQu"
      },
      "source": [
        "특정 컬럼 ( series ) 만 추출하고 싶다면 다음과 같이 추출할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1wHQpby5ZWQu"
      },
      "source": [
        "df['A'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBR3hrGiZWQu"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 다음과 같은 테이블을 직접 만들어보자 </font>\n",
        "```\n",
        "\n",
        "2단\t3단\t4단\t5단\t6단\t7단\t8단\t9단\n",
        "0\t4\t6\t8\t10\t12\t14\t16\t18\n",
        "1\t6\t9\t12\t15\t18\t21\t24\t27\n",
        "2\t8\t12\t16\t20\t24\t28\t32\t36\n",
        "3\t10\t15\t20\t25\t30\t35\t40\t45\n",
        "4\t12\t18\t24\t30\t36\t42\t48\t54\n",
        "5\t14\t21\t28\t35\t42\t49\t56\t63\n",
        "6\t16\t24\t32\t40\t48\t56\t64\t72\n",
        "7\t18\t27\t36\t45\t54\t63\t72\t81\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "96uVujqsZWQu"
      },
      "source": [
        "# 연습문제의 코드를 작성하세요\n",
        "import numpy as np \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz2Rl-dZsHRF"
      },
      "source": [
        "df['2단'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep5h8-W-ZWQu"
      },
      "source": [
        "<hr style=\"height:3px\">\n",
        "\n",
        "# 레코드 추출\n",
        "\n",
        "데이터 프레임으로부터 다양한 조건으로 우리가 원하는 특정 행들을 추출할 수 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVtX4QuqZWQu"
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'btype' : ['a','b','o','ab', 'a'],\n",
        "    'height' : [175, 163, 168, 180, 172],\n",
        "    'weight' : [78,56,88,73,77]    \n",
        "})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgu-j1VZWQv"
      },
      "source": [
        "## 데이터 순서로부터 추출\n",
        "\n",
        "head 나 tail 로 앞,뒷쪽 일부 데이터를 추출할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeX1a0NjZWQv"
      },
      "source": [
        "df.tail(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSM53U7dZWQv"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpi7CTdEZWQv"
      },
      "source": [
        "df[1:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOH79NJpZWQv"
      },
      "source": [
        "df[3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObvdVQQZWQv"
      },
      "source": [
        "## 조건으로 추출 (loc)\n",
        "\n",
        "loc 는 db 의 셀렉트 문과 비슷한 일을 해준다. 이를 이용해 다양한 조건으로 데이터를 추출할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IahkLJo8ZWQw"
      },
      "source": [
        "df.loc[ df['btype'] == 'a']\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt4tkPwMZWQw"
      },
      "source": [
        "df.loc[ df['height'] > 170 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNiXLf8zZWQw"
      },
      "source": [
        "& (and)  나 |(or) 를 이용해 조건을 추출할 수도 있다.  다만 각 조건들은 괄호를 붙여주어야 한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiRVTCZZWQw"
      },
      "source": [
        "df.loc[ ( df['height'] > 170 ) & ( df['btype'] == 'a' ) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG0igDSBZWQw"
      },
      "source": [
        "df.loc[ ( df['height'] > 170 ) | ( df['btype'] == 'o' ) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t6Nu6eiZWQw"
      },
      "source": [
        "다음과 같이 특정 컬럼만 추출도 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGOg57exZWQw"
      },
      "source": [
        "df.loc[df['btype'] == 'a', ['height','btype']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u__avdMGZWQx"
      },
      "source": [
        "<hr style=\"height:3px\">\n",
        "\n",
        "# 파일 읽어들이기 \n",
        "\n",
        "pandas 의 장점중에 하나는 데이터파일의 입출력이 편하다는 점이다. pandas 는 다양한 형태의 csv,xls 등의 파일을 디스크로 부터 읽거나 또는 네트워크 상에서 직접 전송받아 열수 있다.  \n",
        "\n",
        "\n",
        "## 파일 읽기 : read_csv\n",
        "\n",
        "다음은 간단한 csv 파일의 예이다. 다음 코드를 실행해서 먼저 이 파일을 다운로드한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WslQNEN5IM82"
      },
      "source": [
        "from urllib import request\n",
        "url  = 'https://raw.githubusercontent.com/decoz/mlclass/master/sample3_2.tsv'\n",
        "fname = 'sample3_2.tsv'\n",
        "request.urlretrieve(url, fname)\n",
        "\n",
        "url  = 'https://raw.githubusercontent.com/decoz/mlclass/master/sample3_1.csv'\n",
        "fname = 'sample3_1.csv'\n",
        "request.urlretrieve(url, fname)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4uOypxhJllQ"
      },
      "source": [
        "코랩 좌측 탭의 파일섹션을 보면 해당 csv 파일이 다운로드 된걸 볼 수 있다. 그러면 이제 그 파일을 읽어들여보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuNTkZdcZWQx"
      },
      "source": [
        "# 파일 읽기 코드\n",
        "file= open('sample3_1.csv', 'r')\n",
        "t = file.read() \n",
        "print(t)\n",
        "file.close() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQUc-L6ZWQx"
      },
      "source": [
        "이제 위의 파일을 data frame 으로 읽어들여보겠다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHehz01-ZWQx"
      },
      "source": [
        "df = pd.read_csv('sample3_1.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2PxwMH4ZWQx"
      },
      "source": [
        "이번에는 다음과 같은 파일을 연다고 쳐보자. 이 파일은 구분자가 tab 으로 되어있고 두명의 시험성적이 누락되어있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr9Uvx65ZWQx"
      },
      "source": [
        "file= open('sample3_2.tsv', 'r')\n",
        "print(file.read())\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fzDoNSkZWQy"
      },
      "source": [
        "이 파일을 그냥 열면 다음과 같은 형태가 된다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ixGSMK3ZWQy"
      },
      "source": [
        "df = pd.read_csv('sample3_2.tsv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwd3i3GBZWQy"
      },
      "source": [
        "이는 다음과 같이 sep 값을 이용해 구분자를 설정해주어야 한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czaCo4czZWQy"
      },
      "source": [
        "df = pd.read_csv('sample3_2.tsv', sep = '\\t')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmk3g6U5ZWQy"
      },
      "source": [
        "## NaN \n",
        "\n",
        "위의 예제를 보면 시험성적의 누락을 표시한 null 이 NaN 으로 바뀐 것을 볼 수 있다. NaN 은 'Not a Number' 의 약자로서 원래는 devide by zero 등의 invalid data 를 의미하며 데이터 과학에서는 측정되지 안은 데이터나 오류가 난 데이터로 missing data 로도 자주 사용된다. \n",
        "\n",
        "리얼데이터에서는 다양한 형태로 이런 NaN 데이터를 표기하기 때문에 특정 표기를 NaN으로 인식하는 옵션이 필요한 경우도 있다. 위의 예제에서 김성일시의 키가 None 으로 표기된 걸 볼 수 있을 것이다. 이런 추가 표기를 반영할때는 na_values 옵션을 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjt0sPi-ZWQy"
      },
      "source": [
        "df = pd.read_csv('sample3_2.tsv', sep = '\\t', na_values = ['None'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sEis_HW1cLw"
      },
      "source": [
        "df['height'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-uXg2qZZWQz"
      },
      "source": [
        "df 를 처리시에 이러한 NaN 데이터를 일정 수치로 채워야 하는 경우도 있다. 다음 구문은 NaN을 모두 0 으로 채워준다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNgZ1z3zZWQz"
      },
      "source": [
        "df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVaF-cyiZWQz"
      },
      "source": [
        "또는 NaN 을 빼고 처리해야 하는 경우도 있다.  다음은 score 와 height 에서 NaN 이 없는 데이터만 출력해준다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdL8ckZZWQz"
      },
      "source": [
        "df = pd.read_csv('sample3_2.tsv', sep = '\\t', na_values = ['None'])\n",
        "df\n",
        "df.loc[ df['height'].notna() & df['score'].notna() ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quJ_tnJZZWQz"
      },
      "source": [
        "## 네트워크 상에서 직접 파일을 읽어들이기 \n",
        "\n",
        "웹상의 간단한 데이터파일을 읽을 때는 굳이 파일을 다운로드 받아 저장하는 과정이 번거로울 수가 있다. 이런 경우를 대비해 pandas의 read_csv 는 직접적인 url 접근도 허용하고 있다. 다음의 예제를 보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peteV1ugZWQz"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8SIT3g2hfH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqXZ5ak2ZWQz"
      },
      "source": [
        "파일명을 url 로 변환한것만으로 데이터가 직접 네트워크 상으로 로딩된 것을 볼 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkIPyxzwZWQ0"
      },
      "source": [
        "위의 데이터에서 하나의 칼럼 값을 뽑아낼 때는 df['칼럼이름'] 이라고 작성해주면 된다. 그러나 칼럼 이름이 상당히 긴 경우(마지막 칼럼) 이를 직접 입력하기 힘들 수가 있다. 이때는 다음과 같이 n 번째 칼럼을 억세스할 수 있다. 예를 들어 마지막 10번째 칼럼이라면 loc 를 이용하여 다음과 같이 추출이 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AQY3_t4ZWQ0"
      },
      "source": [
        "print( df.columns[10] ) \n",
        "\n",
        "df.loc[ :, [df.columns[10]] ] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-TlPyJNZWQ0"
      },
      "source": [
        "이번엔 다음 url 의 데이터를 읽어봅시다. \n",
        "```\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/00409/Daily_Demand_Forecasting_Orders.csv\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRczg9ifZWQ0"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00409/Daily_Demand_Forecasting_Orders.csv', sep = ';')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrx_OTo7ZWQ0"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 위 데이터의 Non-urgent order 의 그래프를 그려보자 </font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7SdlLm2ZWQ0"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "# 여기에 그래프 생성 루틴을 그려보세요 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR5nWueWZWQ0"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 위 데이터중에 월요일의 Target (Total orders) 의 그래프를 그려보자 (Day of the week (Monday to Friday) == 2) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi4ZtChtZWQ1"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "# 여기에 그래프 생성 루틴을 그려보세요 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqnQ2TEFZWQ1"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 위 데이터중에 Order B 와 Total Order 의 상관관계 그래프를 그려보자 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHJ5xkFrZWQ1"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "for i in range(len(df.columns) ):\n",
        "  print(i,\":\", df.columns[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzT4PofxBeg-"
      },
      "source": [
        "x = df[ df.columns[4] ].values\n",
        "y = df[ df.columns[-1] ].values\n",
        "\n",
        "plt.plot(x,y,'.')\n",
        "plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA3Xfl4cDO8l"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit( x.reshape(-1,1), y ) \n",
        "print( model.score(x.reshape(-1,1), y  ) )\n",
        "\n",
        "plt.plot( x, y,'.')\n",
        "plt.plot( x, x * model.coef_ + model.intercept_ )\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgYIzv0WZWQ1"
      },
      "source": [
        "## 엑셀 파일을 읽어들이기 \n",
        "\n",
        "엑셀파일도 read_csv 를 read_excel 로 읽어들이기만 하면 간단하다.  다만 혹시라도 \" xlrd 어쩌구.. \" 하는 에러가 난다면 그땐 다음 구문으로 xrld 라이브러리를 설치해주자. \n",
        "\n",
        "- pip install xlrd\n",
        "\n",
        "다음은 간단한 엑셀파일을 읽어들이는 예제이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yEE2ZLy2ZWQ1"
      },
      "source": [
        "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00424/2014%20and%202015%20CSM%20dataset.xlsx')\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR_72FVtZWQ1"
      },
      "source": [
        "### <font color = 'red'> 연습문제 : 위의 엑셀데이터로 회귀분석을 해보자 </font>\n",
        "\n",
        "위의 데이터는 영화 관련 자료의 데이터이다. 위의 자료중에 Screens 와 Budget 의 관계를 다양한 형태로 회귀분석해보고 둘의 결정계수를 얻어보자\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFwEbh5ZWQ1"
      },
      "source": [
        "from sklearn import linear_model\n",
        "# 연습문제의 코드를 작성하세요\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSDv2ZbpZWQ2"
      },
      "source": [
        "\n",
        "### <font color = 'red'> 연습문제 : uci 공인 데이터들로 회귀분석을 해보자 </font>\n",
        "\n",
        "다음의 url 은 머신러닝 공인 데이터로 유명한 uci 데이터중에 회귀분석용 자료들의 모음이다. 다양한 형태의 데이터가 있으며 경우에 따라 그 용량이 방대한 경우도 존재한다. 또한 NaN 데이터가 많이 들어있는 경우가 많다. 위 자료들중에 선형성이 있다고 생각되는 두 필드를 찾아 회귀분석을 해보자 </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "e1sfDXQ_ZWQ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIktR3VUZWQ3"
      },
      "source": [
        "\n",
        "\n",
        "<hr style=\"height:3px\">\n",
        "\n",
        "#  sklearn 샘플 데이터셋\n",
        "\n",
        "sklearn 라이브러리는 손쉽게 러닝을 테스트할수 있도롟 sklearn.dartaset 에 간단한 샘플예제들을 제공한다. 여러 종류의 문제들이 있지만 지금까지 배운 회귀분석을 테스트 할 수 있는 데이터들을 알아보자. \n",
        "\n",
        "- load_boston([return_X_y])\tLoad and return the boston house-prices dataset (regression).\n",
        "- load_diabetes([return_X_y])\tLoad and return the diabetes dataset (regression).\n",
        "- load_linnerud([return_X_y])\tLoad and return the linnerud dataset (multivariate regression).\n",
        "\n",
        "\n",
        "## sklearn dataset 읽고 사용하기 \n",
        "\n",
        "저중에서 당뇨병 환자의 데이터를 다룬 diabetes를 읽어들여보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wMOH84FZWQ3"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "diabetes = datasets.load_diabetes()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtyaWKxmZWQ3"
      },
      "source": [
        "sklearn dataset 은 데이터만이 아니라 데이터에 대한 설명 및  feature 이름 그리고  target 에 따로 y데이터를 담아둔다. \n",
        "\n",
        "- DESCR : 데이터에 대한 설명 ( text ) \n",
        "- feature_names : 각 칼럼의 이름 \n",
        "- data : 예측을 위한 근거 데이터\n",
        "- target : 예측의 대상 데이터\n",
        "\n",
        "데이터에 대한 설명을 한번보자 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9CiKuqFZWQ3"
      },
      "source": [
        "print(diabetes.DESCR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyh7c9ATZWQ3"
      },
      "source": [
        "이번엔 데이터를 소스 데이터를 dataframe 형태로 읽어들이도록 하겠다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qb9MKa1ZWQ3"
      },
      "source": [
        "df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAVd4Oh-ZWQ3"
      },
      "source": [
        "이번엔 타겟데이터를 보자 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HDKRQxKZWQ4"
      },
      "source": [
        "target = pd.DataFrame(diabetes.target)\n",
        "target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHvDYaenZWQ4"
      },
      "source": [
        "\n",
        "## 칼럼간의 관계를 분석하기\n",
        "\n",
        "위 데이터처럼 다수의 인자(attribute)를 지닌 데이터간의 상관관계를 분석하는 것은 쉬운 일이 아니다. 다행히 seaborn 이라는 라이브러리를 사용하면 이들의 관계를 도식화할 수 있다. \n",
        "\n",
        "먼저 s1,s2,s3 의 데이터의 상관관계를 도식화하하는 예를 보자 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M98D0m6WZWQ4"
      },
      "source": [
        "import seaborn as sns\n",
        "cols = [\"s1\", \"s2\", \"s3\"]\n",
        "\n",
        "sns.pairplot(df[cols].sample(100))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5u_T20LZWQ4"
      },
      "source": [
        "s2와 s1이 선형적 관계를 지녔음을 알수있다. 하지만 가장 중요한 것은 target 과의 관계일 것이다. \n",
        "이번엔 여기에 target 을 포함해서 관계를 알아보자 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QWfaJ9EPZWQ4"
      },
      "source": [
        "df[\"target\"] = target\n",
        "cols = np.append( cols, [\"target\"])\n",
        "sns.pairplot(df[cols])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQqbAvWdZWQ4"
      },
      "source": [
        "\n",
        "### <font color = 'red'> 연습문제 : iris 데이터 분석 \n",
        "\n",
        "이제 load_boston 를 이용해 위의 과정을 직접 해보고 선형성이 보이는 필드들에 대해 회귀분석을 수행해보자.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLEA-nxSZWQ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}